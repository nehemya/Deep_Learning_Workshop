{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Elo contest.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"gqBQhPAbYyGW","colab_type":"text"},"cell_type":"markdown","source":["# Elo contest\n","created by Elior Nehemya & Eden Levy\n","\n","---\n","\n","Elo competition focused on "]},{"metadata":{"id":"eBw-EqN5KseM","colab_type":"code","outputId":"9526fe7a-11f0-4ffc-9bef-0283cf2e0ad4","executionInfo":{"status":"ok","timestamp":1545512682207,"user_tz":-120,"elapsed":2008,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.linear_model import LogisticRegression, Lasso\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn import preprocessing\n","import matplotlib.pyplot as plt\n","from scipy import stats\n","from sklearn.ensemble import RandomForestClassifier\n","import lightgbm as lgb\n","import time\n","\n","from keras.models import Model, Sequential\n","from keras.datasets import mnist\n","from keras.layers import Dense, Conv2D, Flatten, Input,Dropout,BatchNormalization, Embedding, concatenate\n","from keras.regularizers import l2\n","from keras.utils import to_categorical\n","from keras import regularizers\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, confusion_matrix\n","from math import sqrt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"20KnrvskK1be","colab_type":"code","outputId":"25e6160c-6f44-4eb9-e268-d67a8f1f9858","executionInfo":{"status":"ok","timestamp":1545496191026,"user_tz":-120,"elapsed":643,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"6kN9KMCu82U2","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/train.csv')\n","df_test = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/test.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4UwEmsdwau_V","colab_type":"text"},"cell_type":"markdown","source":["Loading the data"]},{"metadata":{"id":"rZp4MQdya-3N","colab_type":"text"},"cell_type":"markdown","source":["# Starting from the bottom!!\n","Creating a baseline ML prediction just from train.csv"]},{"metadata":{"id":"UGkuKPiawsbu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"790ef995-add7-402f-8154-db8b2c8e3ab0","executionInfo":{"status":"ok","timestamp":1545496357804,"user_tz":-120,"elapsed":472,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}}},"cell_type":"code","source":["df_train.head()"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_active_month</th>\n","      <th>card_id</th>\n","      <th>feature_1</th>\n","      <th>feature_2</th>\n","      <th>feature_3</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-06</td>\n","      <td>C_ID_92a2005557</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>-0.820283</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-01</td>\n","      <td>C_ID_3d0044924f</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.392913</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2016-08</td>\n","      <td>C_ID_d639edf6cd</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0.688056</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-09</td>\n","      <td>C_ID_186d6a6901</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0.142495</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-11</td>\n","      <td>C_ID_cdbd2c0db2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>-0.159749</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n","0            2017-06  C_ID_92a2005557          5          2          1   \n","1            2017-01  C_ID_3d0044924f          4          1          0   \n","2            2016-08  C_ID_d639edf6cd          2          2          0   \n","3            2017-09  C_ID_186d6a6901          4          3          0   \n","4            2017-11  C_ID_cdbd2c0db2          1          3          0   \n","\n","     target  \n","0 -0.820283  \n","1  0.392913  \n","2  0.688056  \n","3  0.142495  \n","4 -0.159749  "]},"metadata":{"tags":[]},"execution_count":49}]},{"metadata":{"id":"Y8pTWyVDOSLK","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = df_train.iloc[:,2:]\n","X_train = X_train.drop(['target'], axis=1)\n","Y_train = df_train['target']\n","\n","x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=10)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PY8RH6_BwSZt","colab_type":"text"},"cell_type":"markdown","source":["baseline models:"]},{"metadata":{"id":"LzNej5xjNDnJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c94e713f-606f-4503-d00b-db2a0e85060d","executionInfo":{"status":"ok","timestamp":1545496550796,"user_tz":-120,"elapsed":665,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}}},"cell_type":"code","source":["clf = Lasso(alpha=0.2)\n","clf.fit(x_train,y_train)\n","\n","clf_pred = clf.predict(x_test)\n","rms = sqrt(mean_squared_error(y_test, clf_pred))\n","print(rms)\n"],"execution_count":55,"outputs":[{"output_type":"stream","text":["3.8008292845419827\n"],"name":"stdout"}]},{"metadata":{"id":"1X6lZ6Q1LZZU","colab_type":"code","colab":{}},"cell_type":"code","source":["toPred = df_test.iloc[:,2:]\n","pred2 = clf.predict(toPred)\n","sub = pd.DataFrame(data=df_test.iloc[:,1])\n","sub['target'] = pred2\n","sub.to_csv('submission4.csv', encoding='utf-8', index=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5Owx0Z32WKT8","colab_type":"code","colab":{}},"cell_type":"code","source":["svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n","svr_rbf.fit(x_train, y_train)\n","\n","svr_pred_test = svr_rbf.predict(x_test)\n","rms = sqrt(mean_squared_error(y_test, svr_pred_test))\n","print(rms)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DYSH9hyPZCPV","colab_type":"code","outputId":"0f8788d4-5977-4bbd-d896-1f1ef2cbea25","executionInfo":{"status":"ok","timestamp":1545496486863,"user_tz":-120,"elapsed":637,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["regr_1 = DecisionTreeRegressor(max_depth=5)\n","regr_1.fit(x_train, y_train)\n","pred = regr_1.predict(x_test)\n","rms = sqrt(mean_squared_error(y_test, pred))\n","print(rms)\n","\n"],"execution_count":53,"outputs":[{"output_type":"stream","text":["3.8002729686269037\n"],"name":"stdout"}]},{"metadata":{"id":"4tfRIBKg1xdj","colab_type":"code","colab":{}},"cell_type":"code","source":["toPred = df_test.iloc[:,2:]\n","pred2 = regr_1.predict(toPred)\n","sub = pd.DataFrame(data=df_test.iloc[:,1])\n","sub['target'] = pred2\n","sub.to_csv('submission2.csv', encoding='utf-8', index=False)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PCgvPTMkPGBX","colab_type":"code","colab":{}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(9, activation='elu', input_shape=(3,)))\n","model.add(BatchNormalization())\n","model.add(Dense(6, activation='elu'))\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_train,Y_train,validation_split=0.2,shuffle=True,epochs=10)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yoSCcRQdUGp3","colab_type":"text"},"cell_type":"markdown","source":["# Category Embeding\n","Here we will use category embeding in order to get more information from our category features\n"]},{"metadata":{"id":"cgQ3kd0Gpx0K","colab_type":"code","colab":{}},"cell_type":"code","source":["data = X_train[:]\n","F1 = {p:i for (i,p) in enumerate(data['feature_1'].unique())}\n","F2 = {p:i for (i,p) in enumerate(data['feature_2'].unique())}\n","F3 = {p:i for (i,p) in enumerate(data['feature_3'].unique())}\n","\n","processed_data = data.copy()\n","processed_data['F1'] = [F1[x] for x in data['feature_1']]\n","processed_data['F2'] = [F2[x] for x in data['feature_2']]\n","processed_data['F3'] = [F3[x] for x in data['feature_3']]\n","processed_data = processed_data.loc[:,'F1':'F3']\n","\n","target = Y_train[:]\n","\n","F1_inp = Input(shape=(1,),dtype='int64')\n","F2_inp = Input(shape=(1,),dtype='int64')\n","F3_inp = Input(shape=(1,),dtype='int64')\n","\n","F1_emb = Embedding(len(F1),4,input_length=1, embeddings_regularizer=l2(1e-6))(F1_inp)\n","F2_emb = Embedding(len(F2),2,input_length=1, embeddings_regularizer=l2(1e-6))(F2_inp)\n","F3_emb = Embedding(len(F3),2,input_length=1, embeddings_regularizer=l2(1e-6))(F3_inp)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4K2Jp-IXuhqa","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","x = concatenate([F1_emb,F2_emb,F3_emb], name='concat')\n","\n","x = Flatten()(x)\n","\n","x = Dense(64,activation='relu')(x)\n","x = Dense(128,activation='relu')(x)\n","x = Dense(64,activation='relu')(x)\n","x = Dense(1, activation='linear')(x)\n","nn_model = Model([F1_inp,F2_inp,F3_inp],x)\n","nn_model.compile(loss = 'mse',optimizer='adam')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iYNf6LUTx-_e","colab_type":"code","outputId":"e4ed15d6-d775-4a42-b4d0-c32b2d5f27c5","executionInfo":{"status":"ok","timestamp":1545507795014,"user_tz":-120,"elapsed":97183,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"cell_type":"code","source":["history1 = nn_model.fit([processed_data['F1'],processed_data['F2'],processed_data['F3']],target,validation_split=0.2,epochs=10)"],"execution_count":81,"outputs":[{"output_type":"stream","text":["Train on 161533 samples, validate on 40384 samples\n","Epoch 1/10\n","161533/161533 [==============================] - 11s 66us/step - loss: 14.6920 - val_loss: 15.3615\n","Epoch 2/10\n","161533/161533 [==============================] - 10s 59us/step - loss: 14.6874 - val_loss: 15.3621\n","Epoch 3/10\n","161533/161533 [==============================] - 9s 58us/step - loss: 14.6855 - val_loss: 15.3543\n","Epoch 4/10\n","161533/161533 [==============================] - 9s 59us/step - loss: 14.6837 - val_loss: 15.3696\n","Epoch 5/10\n","161533/161533 [==============================] - 9s 59us/step - loss: 14.6847 - val_loss: 15.3573\n","Epoch 6/10\n","161533/161533 [==============================] - 9s 59us/step - loss: 14.6811 - val_loss: 15.3584\n","Epoch 7/10\n","161533/161533 [==============================] - 9s 58us/step - loss: 14.6832 - val_loss: 15.3538\n","Epoch 8/10\n","161533/161533 [==============================] - 9s 58us/step - loss: 14.6834 - val_loss: 15.3538\n","Epoch 9/10\n","161533/161533 [==============================] - 9s 58us/step - loss: 14.6831 - val_loss: 15.3542\n","Epoch 10/10\n","161533/161533 [==============================] - 9s 59us/step - loss: 14.6826 - val_loss: 15.3539\n"],"name":"stdout"}]},{"metadata":{"id":"X_n_DZ2Mu82P","colab_type":"code","outputId":"8b85f16b-02ca-4dd2-a6fe-757bc11c4fb3","executionInfo":{"status":"ok","timestamp":1545512703519,"user_tz":-120,"elapsed":1335,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["pred_data = x_test[:]\n","processed_pred = pred_data.copy()\n","processed_pred['F1'] = [F1[x] for x in pred_data['feature_1']]\n","processed_pred['F2'] = [F2[x] for x in pred_data['feature_2']]\n","processed_pred['F3'] = [F3[x] for x in pred_data['feature_3']]\n","processed_pred = processed_pred.loc[:,'F1':'F3']\n","\n","\n","x_test1 = [processed_pred[f] for f in processed_data.columns]\n","\n","y_predicted = nn_model.predict(x_test1)\n","rms = np.sqrt(mean_squared_error(y_test, y_predicted))\n","print (rms)\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["3.8191095017851704\n"],"name":"stdout"}]},{"metadata":{"id":"J573kzCGXpny","colab_type":"code","colab":{}},"cell_type":"code","source":["nn_model.save_weights('/content/gdrive/My Drive/Colab Notebooks/project_2/my_embedding_weights.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qYczm5eT8NcK","colab_type":"text"},"cell_type":"markdown","source":["now we will try add more features to our model"]},{"metadata":{"id":"cauC9-y84Oo0","colab_type":"code","colab":{}},"cell_type":"code","source":["nn_model.load_weights('/content/gdrive/My Drive/Colab Notebooks/project_2/my_embedding_weights.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pO-hkyZfaVPK","colab_type":"text"},"cell_type":"markdown","source":["now we will use embedding together with new data v1"]},{"metadata":{"id":"yfgUPouea0wS","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train_v1 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/train_merge_new_transactions.csv')\n","df_test_v1 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/test_merge_new_transactions.csv')\n","X_train = df_train_v1.iloc[:,7:]\n","#X_train = X_train.drop(['target'], axis=1)\n","#X_scaled = preprocessing.scale(X_train)\n","#X_scaled = pd.DataFrame(data=X_scaled)\n","Y_train = df_train_v1['target']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yx_V0dP5pbyx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e59a8ff2-232c-40b1-f97f-98cbeb3c1e62","executionInfo":{"status":"ok","timestamp":1545512732551,"user_tz":-120,"elapsed":603,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}}},"cell_type":"code","source":["X_train.shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(201917, 21)"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"pKOSpNBKZjBY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"784fa05d-b687-4cac-d476-9fe329a77298","executionInfo":{"status":"ok","timestamp":1545512757843,"user_tz":-120,"elapsed":900,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}}},"cell_type":"code","source":["emb_model = Model(input = nn_model.input, output = nn_model.get_layer('concat').output)\n","emb_out = emb_model.predict(x_test1)\n","new_train = X_train\n","\n","emb_out = emb_out.reshape((emb_out.shape[0]), emb_out.shape[2])\n","pred =  pd.DataFrame(emb_out)\n","new_train = pd.concat([new_train, pred], axis=1)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"co...)`\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"metadata":{"id":"Ou4leBnmqBhm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"02a41e3c-a639-4036-8fbc-be1293a97231","executionInfo":{"status":"ok","timestamp":1545512969723,"user_tz":-120,"elapsed":772,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}}},"cell_type":"code","source":["new_train.shape"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(201917, 29)"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"kJAB2vmcn1WG","colab_type":"code","colab":{}},"cell_type":"code","source":["inp = Input(shape=(29,))\n","z = Dense(128, activation='relu')(inp)\n","z = Dense(256, activation='relu')(z)\n","z = Dense(256, activation='relu')(z)\n","z = Dense(1, activation='linear')(z)\n","\n","model = Model(inputs = inp, outputs= z )\n","model.compile(loss = 'mse', optimizer = 'adam', )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I6dnvJcfZi-r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":282},"outputId":"e8598ca5-fff2-4195-935e-03d14a195612","executionInfo":{"status":"error","timestamp":1545513148016,"user_tz":-120,"elapsed":606,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}}},"cell_type":"code","source":["history = model.fit(new_train, Y_train, batch_size=64, epochs=5)\n"],"execution_count":26,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-e77e584c71ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'target'"]}]},{"metadata":{"id":"Smgy4ew8Rzy6","colab_type":"text"},"cell_type":"markdown","source":["# Adding more features v1\n"]},{"metadata":{"id":"0hRTx0rN6BD4","colab_type":"text"},"cell_type":"markdown","source":["working on prepared data v1 only new marchent transactions merge\n"]},{"metadata":{"id":"xB2pvHt1A0dI","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train_v1 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/train_merge_new_transactions.csv')\n","df_test_v1 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/test_merge_new_transactions.csv')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X03ZungJA0aW","colab_type":"code","outputId":"9ecc30bf-9e21-478e-dbaa-4e15430d647a","executionInfo":{"status":"ok","timestamp":1545322506796,"user_tz":-120,"elapsed":644,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":917}},"cell_type":"code","source":["df_train_v1.head().T"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Unnamed: 0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>first_active_month</th>\n","      <td>2017-06-01</td>\n","      <td>2017-01-01</td>\n","      <td>2016-08-01</td>\n","      <td>2017-09-01</td>\n","      <td>2017-11-01</td>\n","    </tr>\n","    <tr>\n","      <th>card_id</th>\n","      <td>C_ID_92a2005557</td>\n","      <td>C_ID_3d0044924f</td>\n","      <td>C_ID_d639edf6cd</td>\n","      <td>C_ID_186d6a6901</td>\n","      <td>C_ID_cdbd2c0db2</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1</th>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>feature_2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>feature_3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>target</th>\n","      <td>-0.820283</td>\n","      <td>0.392913</td>\n","      <td>0.688056</td>\n","      <td>0.142495</td>\n","      <td>-0.159749</td>\n","    </tr>\n","    <tr>\n","      <th>elapsed_time</th>\n","      <td>245</td>\n","      <td>396</td>\n","      <td>549</td>\n","      <td>153</td>\n","      <td>92</td>\n","    </tr>\n","    <tr>\n","      <th>new_transactions_count</th>\n","      <td>23</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_sum</th>\n","      <td>-13.24</td>\n","      <td>-4.355</td>\n","      <td>-0.7</td>\n","      <td>-4.656</td>\n","      <td>-19.92</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_mean</th>\n","      <td>-0.5757</td>\n","      <td>-0.726</td>\n","      <td>-0.7</td>\n","      <td>-0.665</td>\n","      <td>-0.5537</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_max</th>\n","      <td>-0.2961</td>\n","      <td>-0.7017</td>\n","      <td>-0.7</td>\n","      <td>-0.567</td>\n","      <td>0.451</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_min</th>\n","      <td>-0.7246</td>\n","      <td>-0.7393</td>\n","      <td>-0.7</td>\n","      <td>-0.7344</td>\n","      <td>-0.7393</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_std</th>\n","      <td>0.1357</td>\n","      <td>0.01438</td>\n","      <td>0</td>\n","      <td>0.0659</td>\n","      <td>0.2239</td>\n","    </tr>\n","    <tr>\n","      <th>new_installments_sum</th>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>new_installments_mean</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.714286</td>\n","      <td>0.972222</td>\n","    </tr>\n","    <tr>\n","      <th>new_installments_max</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>new_installments_min</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>new_installments_std</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.755929</td>\n","      <td>0.376913</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_month_mean</th>\n","      <td>3.47826</td>\n","      <td>2.5</td>\n","      <td>4</td>\n","      <td>3.71429</td>\n","      <td>3.55556</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_month_max</th>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_month_min</th>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_month_std</th>\n","      <td>0.510754</td>\n","      <td>0.547723</td>\n","      <td>0</td>\n","      <td>0.48795</td>\n","      <td>0.503953</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_date_ptp</th>\n","      <td>4.74231e+06</td>\n","      <td>4.88763e+06</td>\n","      <td>0</td>\n","      <td>3.62550e+06</td>\n","      <td>4.94968e+06</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_date_max</th>\n","      <td>1.525e+09</td>\n","      <td>1.52239e+09</td>\n","      <td>1.52494e+09</td>\n","      <td>1.52405e+09</td>\n","      <td>1.52494e+09</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_date_min</th>\n","      <td>1.52026e+09</td>\n","      <td>1.5175e+09</td>\n","      <td>1.52494e+09</td>\n","      <td>1.52042e+09</td>\n","      <td>1.51999e+09</td>\n","    </tr>\n","    <tr>\n","      <th>new_month_lag_min</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>new_month_lag_max</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        0                1                2  \\\n","Unnamed: 0                              0                1                2   \n","first_active_month             2017-06-01       2017-01-01       2016-08-01   \n","card_id                   C_ID_92a2005557  C_ID_3d0044924f  C_ID_d639edf6cd   \n","feature_1                               5                4                2   \n","feature_2                               2                1                2   \n","feature_3                               1                0                0   \n","target                          -0.820283         0.392913         0.688056   \n","elapsed_time                          245              396              549   \n","new_transactions_count                 23                6                1   \n","new_purchase_amount_sum            -13.24           -4.355             -0.7   \n","new_purchase_amount_mean          -0.5757           -0.726             -0.7   \n","new_purchase_amount_max           -0.2961          -0.7017             -0.7   \n","new_purchase_amount_min           -0.7246          -0.7393             -0.7   \n","new_purchase_amount_std            0.1357          0.01438                0   \n","new_installments_sum                    0                6                0   \n","new_installments_mean                   0                1                0   \n","new_installments_max                    0                1                0   \n","new_installments_min                    0                1                0   \n","new_installments_std                    0                0                0   \n","new_purchase_month_mean           3.47826              2.5                4   \n","new_purchase_month_max                  4                3                4   \n","new_purchase_month_min                  3                2                4   \n","new_purchase_month_std           0.510754         0.547723                0   \n","new_purchase_date_ptp         4.74231e+06      4.88763e+06                0   \n","new_purchase_date_max           1.525e+09      1.52239e+09      1.52494e+09   \n","new_purchase_date_min         1.52026e+09       1.5175e+09      1.52494e+09   \n","new_month_lag_min                       1                1                2   \n","new_month_lag_max                       2                2                2   \n","\n","                                        3                4  \n","Unnamed: 0                              3                4  \n","first_active_month             2017-09-01       2017-11-01  \n","card_id                   C_ID_186d6a6901  C_ID_cdbd2c0db2  \n","feature_1                               4                1  \n","feature_2                               3                3  \n","feature_3                               0                0  \n","target                           0.142495        -0.159749  \n","elapsed_time                          153               92  \n","new_transactions_count                  7               36  \n","new_purchase_amount_sum            -4.656           -19.92  \n","new_purchase_amount_mean           -0.665          -0.5537  \n","new_purchase_amount_max            -0.567            0.451  \n","new_purchase_amount_min           -0.7344          -0.7393  \n","new_purchase_amount_std            0.0659           0.2239  \n","new_installments_sum                    5               35  \n","new_installments_mean            0.714286         0.972222  \n","new_installments_max                    1                2  \n","new_installments_min                   -1               -1  \n","new_installments_std             0.755929         0.376913  \n","new_purchase_month_mean           3.71429          3.55556  \n","new_purchase_month_max                  4                4  \n","new_purchase_month_min                  3                3  \n","new_purchase_month_std            0.48795         0.503953  \n","new_purchase_date_ptp         3.62550e+06      4.94968e+06  \n","new_purchase_date_max         1.52405e+09      1.52494e+09  \n","new_purchase_date_min         1.52042e+09      1.51999e+09  \n","new_month_lag_min                       1                1  \n","new_month_lag_max                       2                2  "]},"metadata":{"tags":[]},"execution_count":51}]},{"metadata":{"id":"RLICTPZFUC_d","colab_type":"text"},"cell_type":"markdown","source":["adding normalization "]},{"metadata":{"id":"-eu5eJQePoWR","colab_type":"code","outputId":"1ead49b7-1158-433a-a39b-dbd58c5de433","executionInfo":{"status":"ok","timestamp":1545326074634,"user_tz":-120,"elapsed":1421,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["X_train = df_train_v1.iloc[:,7:]\n","#X_train = X_train.drop(['target'], axis=1)\n","X_scaled = preprocessing.scale(X_train)\n","X_scaled = pd.DataFrame(data=X_scaled)\n","Y_train = df_train_v1.iloc[:,6]\n","x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y_train, test_size=0.2, random_state=10)\n","\n","clf = Lasso(alpha=0.2)\n","clf.fit(x_train,y_train)\n","\n","clf_pred = clf.predict(x_test)\n","rms = sqrt(mean_squared_error(y_test, clf_pred))\n","print(rms)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\"Numerical issues were encountered \"\n"],"name":"stderr"},{"output_type":"stream","text":["3.789670319444814\n"],"name":"stdout"}]},{"metadata":{"id":"3i3lj9UwL6YF","colab_type":"text"},"cell_type":"markdown","source":["performing lasso on v1 data got 3.905 at submission"]},{"metadata":{"id":"X62wo1JdA0Mn","colab_type":"code","outputId":"ad2160c0-e2b0-4d00-bb83-2d77502e15e5","executionInfo":{"status":"ok","timestamp":1545322609362,"user_tz":-120,"elapsed":1074,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["X_train = df_train_v1.iloc[:,7:]\n","#X_train = X_train.drop(['target'], axis=1)\n","Y_train = df_train_v1.iloc[:,6]\n","x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=10)\n","\n","clf = Lasso(alpha=0.2)\n","clf.fit(X_train,Y_train)\n","\n","clf_pred = clf.predict(x_test)\n","rms = sqrt(mean_squared_error(y_test, clf_pred))\n","print(rms)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3.7771473173106607\n"],"name":"stdout"}]},{"metadata":{"id":"5OjH3li5BGDU","colab_type":"code","colab":{}},"cell_type":"code","source":["toPred_v1 = df_test_v1.iloc[:,3:]\n","clf_pred = clf.predict(toPred_v1)\n","\n","sub = pd.DataFrame(data=df_test_v1.iloc[:,2])\n","sub['target'] = clf_pred\n","sub.to_csv('submission4.csv', encoding='utf-8', index=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vP2uhyZTHFwU","colab_type":"code","outputId":"44dfbb08-8495-4e57-e3c7-ed36daac0937","executionInfo":{"status":"ok","timestamp":1545318487481,"user_tz":-120,"elapsed":578,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["sub.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(123623, 2)"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"QOxdo5PGMMvn","colab_type":"text"},"cell_type":"markdown","source":["new attemp over v1 data now we will form nn model under scaled data\n","\n","*   got 3.830 rmse nice!!!\n","   \n","\n","\n","\n","\n"]},{"metadata":{"id":"j1wn4IMKKNM0","colab_type":"code","outputId":"0552500e-66a1-43be-f6d5-5fe40f0d8ba7","executionInfo":{"status":"ok","timestamp":1545325099643,"user_tz":-120,"elapsed":162035,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":663}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(50, activation='relu', input_shape=(21,)))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=10)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_56 (Dense)             (None, 50)                1100      \n","_________________________________________________________________\n","dense_57 (Dense)             (None, 100)               5100      \n","_________________________________________________________________\n","dense_58 (Dense)             (None, 256)               25856     \n","_________________________________________________________________\n","dense_59 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","dense_60 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 98,105\n","Trainable params: 98,105\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/10\n","161533/161533 [==============================] - 17s 106us/step - loss: 14.2289 - val_loss: 14.7429\n","Epoch 2/10\n","161533/161533 [==============================] - 16s 100us/step - loss: 14.1095 - val_loss: 14.7869\n","Epoch 3/10\n","161533/161533 [==============================] - 16s 100us/step - loss: 14.0880 - val_loss: 14.7290\n","Epoch 4/10\n","161533/161533 [==============================] - 16s 98us/step - loss: 14.0587 - val_loss: 14.7044\n","Epoch 5/10\n","161533/161533 [==============================] - 16s 97us/step - loss: 14.0369 - val_loss: 14.6821\n","Epoch 6/10\n","161533/161533 [==============================] - 16s 99us/step - loss: 14.0125 - val_loss: 14.7163\n","Epoch 7/10\n","161533/161533 [==============================] - 16s 99us/step - loss: 13.9960 - val_loss: 14.8395\n","Epoch 8/10\n","161533/161533 [==============================] - 16s 98us/step - loss: 13.9937 - val_loss: 14.7136\n","Epoch 9/10\n","161533/161533 [==============================] - 16s 97us/step - loss: 13.9810 - val_loss: 14.6864\n","Epoch 10/10\n","161533/161533 [==============================] - 16s 101us/step - loss: 13.9722 - val_loss: 14.6426\n"],"name":"stdout"}]},{"metadata":{"id":"HA9WAxtXNnn3","colab_type":"code","outputId":"0c99e7cc-000f-4463-8e57-e3f9b9b955b2","executionInfo":{"status":"ok","timestamp":1545325299219,"user_tz":-120,"elapsed":5172,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["toPred_scalev1 = preprocessing.scale(df_test_v1.iloc[:,6:])\n","\n","pred_nn_v1 = model.predict(toPred_scalev1)\n","sub = pd.DataFrame(data=df_test_v1.iloc[:,2])\n","sub['target'] = pred_nn_v1\n","sub.to_csv('submission5.csv', encoding='utf-8', index=False)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\"Numerical issues were encountered \"\n"],"name":"stderr"}]},{"metadata":{"id":"k-RgTr9VmEBU","colab_type":"text"},"cell_type":"markdown","source":["adding some modifications to nn model\n"]},{"metadata":{"id":"5ebo8wY7mDS7","colab_type":"code","outputId":"10616b19-2189-4215-aaab-e779e6e10a1c","executionInfo":{"status":"ok","timestamp":1545326747088,"user_tz":-120,"elapsed":307300,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":799}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(128, activation='relu', input_shape=(21,)))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=20)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_66 (Dense)             (None, 128)               2816      \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 128)               512       \n","_________________________________________________________________\n","dense_67 (Dense)             (None, 256)               33024     \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_68 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_69 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_70 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 171,265\n","Trainable params: 169,473\n","Non-trainable params: 1,792\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/10\n","161533/161533 [==============================] - 33s 207us/step - loss: 14.4429 - val_loss: 14.8200\n","Epoch 2/10\n","161533/161533 [==============================] - 31s 189us/step - loss: 14.2663 - val_loss: 14.7470\n","Epoch 3/10\n","161533/161533 [==============================] - 31s 190us/step - loss: 14.2011 - val_loss: 14.8342\n","Epoch 4/10\n","161533/161533 [==============================] - 30s 187us/step - loss: 14.1419 - val_loss: 14.7023\n","Epoch 5/10\n","161533/161533 [==============================] - 30s 186us/step - loss: 14.1079 - val_loss: 14.6679\n","Epoch 6/10\n","161533/161533 [==============================] - 30s 186us/step - loss: 14.0804 - val_loss: 14.7847\n","Epoch 7/10\n","161533/161533 [==============================] - 31s 191us/step - loss: 14.0680 - val_loss: 14.6566\n","Epoch 8/10\n","161533/161533 [==============================] - 30s 186us/step - loss: 14.0507 - val_loss: 14.6486\n","Epoch 9/10\n","161533/161533 [==============================] - 30s 184us/step - loss: 14.0403 - val_loss: 14.6572\n","Epoch 10/10\n","161533/161533 [==============================] - 29s 181us/step - loss: 14.0170 - val_loss: 14.6051\n"],"name":"stdout"}]},{"metadata":{"id":"hlLtlhBJoiz4","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ydP7W-1T8oRy","colab_type":"text"},"cell_type":"markdown","source":["#  Adding more features v2\n","---\n","V2 data created by merging train/test with historical_transactions data\n","\n","\n"]},{"metadata":{"id":"3VOISVzw8tZQ","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train_v2 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/train_merge_history_transactions.csv')\n","df_test_v2 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/test_merge_history_transactions.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ur5DlFGd_3BQ","colab_type":"code","outputId":"f0177d01-5b1e-4acc-cf2e-00b0a555de92","executionInfo":{"status":"ok","timestamp":1545383276528,"user_tz":-120,"elapsed":614,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":270}},"cell_type":"code","source":["df_train_v2.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>first_active_month</th>\n","      <th>card_id</th>\n","      <th>feature_1</th>\n","      <th>feature_2</th>\n","      <th>feature_3</th>\n","      <th>target</th>\n","      <th>elapsed_time</th>\n","      <th>hist_transactions_count</th>\n","      <th>hist_authorized_flag_sum</th>\n","      <th>...</th>\n","      <th>hist_installments_std</th>\n","      <th>hist_purchase_month_mean</th>\n","      <th>hist_purchase_month_max</th>\n","      <th>hist_purchase_month_min</th>\n","      <th>hist_purchase_month_std</th>\n","      <th>hist_purchase_date_ptp</th>\n","      <th>hist_purchase_date_max</th>\n","      <th>hist_purchase_date_min</th>\n","      <th>hist_month_lag_min</th>\n","      <th>hist_month_lag_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2017-06-01</td>\n","      <td>C_ID_92a2005557</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>-0.820283</td>\n","      <td>245</td>\n","      <td>260</td>\n","      <td>247.0</td>\n","      <td>...</td>\n","      <td>0.123314</td>\n","      <td>8.057692</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>3.474193</td>\n","      <td>20977987.0</td>\n","      <td>1.519551e+09</td>\n","      <td>1.498573e+09</td>\n","      <td>-8</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2017-01-01</td>\n","      <td>C_ID_3d0044924f</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.392913</td>\n","      <td>396</td>\n","      <td>350</td>\n","      <td>339.0</td>\n","      <td>...</td>\n","      <td>1.510777</td>\n","      <td>6.220000</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>3.848142</td>\n","      <td>33717687.0</td>\n","      <td>1.517438e+09</td>\n","      <td>1.483720e+09</td>\n","      <td>-12</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2016-08-01</td>\n","      <td>C_ID_d639edf6cd</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0.688056</td>\n","      <td>549</td>\n","      <td>43</td>\n","      <td>41.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>4.558140</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>3.275467</td>\n","      <td>35635623.0</td>\n","      <td>1.519759e+09</td>\n","      <td>1.484123e+09</td>\n","      <td>-13</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2017-09-01</td>\n","      <td>C_ID_186d6a6901</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0.142495</td>\n","      <td>153</td>\n","      <td>77</td>\n","      <td>77.0</td>\n","      <td>...</td>\n","      <td>0.588974</td>\n","      <td>7.740260</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>3.904797</td>\n","      <td>13375339.0</td>\n","      <td>1.519818e+09</td>\n","      <td>1.506443e+09</td>\n","      <td>-5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2017-11-01</td>\n","      <td>C_ID_cdbd2c0db2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>-0.159749</td>\n","      <td>92</td>\n","      <td>133</td>\n","      <td>128.0</td>\n","      <td>...</td>\n","      <td>1.896862</td>\n","      <td>5.406015</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>5.003086</td>\n","      <td>9405641.0</td>\n","      <td>1.519850e+09</td>\n","      <td>1.510445e+09</td>\n","      <td>-3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 30 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0 first_active_month          card_id  feature_1  feature_2  \\\n","0           0         2017-06-01  C_ID_92a2005557          5          2   \n","1           1         2017-01-01  C_ID_3d0044924f          4          1   \n","2           2         2016-08-01  C_ID_d639edf6cd          2          2   \n","3           3         2017-09-01  C_ID_186d6a6901          4          3   \n","4           4         2017-11-01  C_ID_cdbd2c0db2          1          3   \n","\n","   feature_3    target  elapsed_time  hist_transactions_count  \\\n","0          1 -0.820283           245                      260   \n","1          0  0.392913           396                      350   \n","2          0  0.688056           549                       43   \n","3          0  0.142495           153                       77   \n","4          0 -0.159749            92                      133   \n","\n","   hist_authorized_flag_sum         ...          hist_installments_std  \\\n","0                     247.0         ...                       0.123314   \n","1                     339.0         ...                       1.510777   \n","2                      41.0         ...                       0.000000   \n","3                      77.0         ...                       0.588974   \n","4                     128.0         ...                       1.896862   \n","\n","   hist_purchase_month_mean  hist_purchase_month_max  hist_purchase_month_min  \\\n","0                  8.057692                       12                        1   \n","1                  6.220000                       12                        1   \n","2                  4.558140                       12                        1   \n","3                  7.740260                       12                        1   \n","4                  5.406015                       12                        1   \n","\n","   hist_purchase_month_std  hist_purchase_date_ptp  hist_purchase_date_max  \\\n","0                 3.474193              20977987.0            1.519551e+09   \n","1                 3.848142              33717687.0            1.517438e+09   \n","2                 3.275467              35635623.0            1.519759e+09   \n","3                 3.904797              13375339.0            1.519818e+09   \n","4                 5.003086               9405641.0            1.519850e+09   \n","\n","   hist_purchase_date_min  hist_month_lag_min  hist_month_lag_max  \n","0            1.498573e+09                  -8                   0  \n","1            1.483720e+09                 -12                   0  \n","2            1.484123e+09                 -13                   0  \n","3            1.506443e+09                  -5                   0  \n","4            1.510445e+09                  -3                   0  \n","\n","[5 rows x 30 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"1R2eOZl48tXH","colab_type":"code","outputId":"44b05dbf-9376-4520-8e97-4c0983b17954","executionInfo":{"status":"ok","timestamp":1545383354437,"user_tz":-120,"elapsed":904,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["X_train = df_train_v2.iloc[:,7:]\n","#X_train = X_train.drop(['target'], axis=1)\n","X_scaled = preprocessing.scale(X_train)\n","X_scaled = pd.DataFrame(data=X_scaled)\n","Y_train = df_train_v2.iloc[:,6]\n","x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y_train, test_size=0.2, random_state=10)\n","\n","\n","#get some ML banchmark to comper \n","clf = Lasso(alpha=0.2)\n","clf.fit(x_train,y_train)\n","\n","clf_pred = clf.predict(x_test)\n","rms = sqrt(mean_squared_error(y_test, clf_pred))\n","print(rms)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\"Numerical issues were encountered \"\n"],"name":"stderr"},{"output_type":"stream","text":["3.7912113873820426\n"],"name":"stdout"}]},{"metadata":{"id":"Q2wxSwn9BOex","colab_type":"code","colab":{}},"cell_type":"code","source":["X_scaled.describe()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mDvjXl0sB5sg","colab_type":"text"},"cell_type":"markdown","source":["performing nn model over v2 data"]},{"metadata":{"id":"P4OM1MZE8tUt","colab_type":"code","outputId":"873ff7b6-66f0-4989-953d-f5f81e6ea70e","executionInfo":{"status":"ok","timestamp":1545384151495,"user_tz":-120,"elapsed":684843,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":1139}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(128, activation='relu', input_shape=(23,)))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=20)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_6 (Dense)              (None, 128)               3072      \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 128)               512       \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 256)               33024     \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 171,521\n","Trainable params: 169,729\n","Non-trainable params: 1,792\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/20\n","161533/161533 [==============================] - 37s 230us/step - loss: 14.4218 - val_loss: 14.8273\n","Epoch 2/20\n","161533/161533 [==============================] - 35s 215us/step - loss: 14.2361 - val_loss: 14.6054\n","Epoch 3/20\n","161533/161533 [==============================] - 34s 211us/step - loss: 14.1716 - val_loss: 14.6138\n","Epoch 4/20\n","161533/161533 [==============================] - 35s 219us/step - loss: 14.1308 - val_loss: 14.5921\n","Epoch 5/20\n","161533/161533 [==============================] - 34s 211us/step - loss: 14.1288 - val_loss: 14.6109\n","Epoch 6/20\n","161533/161533 [==============================] - 33s 206us/step - loss: 14.0795 - val_loss: 14.5465\n","Epoch 7/20\n","161533/161533 [==============================] - 34s 211us/step - loss: 14.0712 - val_loss: 14.5667\n","Epoch 8/20\n","161533/161533 [==============================] - 34s 212us/step - loss: 14.0614 - val_loss: 14.4698\n","Epoch 9/20\n","161533/161533 [==============================] - 34s 210us/step - loss: 14.0641 - val_loss: 14.4880\n","Epoch 10/20\n","161533/161533 [==============================] - 33s 206us/step - loss: 14.0368 - val_loss: 14.5251\n","Epoch 11/20\n","161533/161533 [==============================] - 34s 208us/step - loss: 14.0227 - val_loss: 14.6388\n","Epoch 12/20\n","161533/161533 [==============================] - 34s 210us/step - loss: 14.0259 - val_loss: 14.6742\n","Epoch 13/20\n","161533/161533 [==============================] - 35s 216us/step - loss: 13.9994 - val_loss: 14.4672\n","Epoch 14/20\n","161533/161533 [==============================] - 34s 211us/step - loss: 13.9805 - val_loss: 14.5986\n","Epoch 15/20\n","161533/161533 [==============================] - 34s 209us/step - loss: 13.9926 - val_loss: 14.5642\n","Epoch 16/20\n","161533/161533 [==============================] - 34s 210us/step - loss: 13.9864 - val_loss: 14.5514\n","Epoch 17/20\n","161533/161533 [==============================] - 34s 209us/step - loss: 13.9768 - val_loss: 14.5108\n","Epoch 18/20\n","161533/161533 [==============================] - 33s 207us/step - loss: 13.9548 - val_loss: 14.5622\n","Epoch 19/20\n","161533/161533 [==============================] - 33s 206us/step - loss: 13.9616 - val_loss: 14.5408\n","Epoch 20/20\n","161533/161533 [==============================] - 33s 207us/step - loss: 13.9312 - val_loss: 14.6013\n"],"name":"stdout"}]},{"metadata":{"id":"mg_NPdRqElLi","colab_type":"code","colab":{}},"cell_type":"code","source":["toPred_scale_v2 = preprocessing.scale(df_test_v2.iloc[:,6:])\n","\n","pred_nn_v2 = model.predict(toPred_scale_v2)\n","sub = pd.DataFrame(data=df_test_v1.iloc[:,2])\n","sub['target'] = pred_nn_v1\n","sub.to_csv('submission5.csv', encoding='utf-8', index=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XcUke_97EwI_","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"rXvZmJIjC9oS","colab_type":"text"},"cell_type":"markdown","source":["less deeper nn model\n","\n","*   got 3.824 !! some improvment from v1\n","\n","\n"]},{"metadata":{"id":"glypO3v_8tSB","colab_type":"code","outputId":"ecb939c5-710a-41d9-9ec2-bf92aeb8246b","executionInfo":{"status":"ok","timestamp":1545386314344,"user_tz":-120,"elapsed":188768,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":697}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(50, activation='relu', input_shape=(23,)))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_47 (Dense)             (None, 50)                1200      \n","_________________________________________________________________\n","dense_48 (Dense)             (None, 100)               5100      \n","_________________________________________________________________\n","dense_49 (Dense)             (None, 256)               25856     \n","_________________________________________________________________\n","dense_50 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_51 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 99,229\n","Trainable params: 98,717\n","Non-trainable params: 512\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/10\n","161533/161533 [==============================] - 20s 122us/step - loss: 14.3518 - val_loss: 14.7433\n","Epoch 2/10\n","161533/161533 [==============================] - 19s 117us/step - loss: 14.1962 - val_loss: 14.5994\n","Epoch 3/10\n","161533/161533 [==============================] - 19s 115us/step - loss: 14.1332 - val_loss: 14.6742\n","Epoch 4/10\n","161533/161533 [==============================] - 18s 113us/step - loss: 14.1028 - val_loss: 14.5217\n","Epoch 5/10\n","161533/161533 [==============================] - 19s 116us/step - loss: 14.0827 - val_loss: 14.6122\n","Epoch 6/10\n","161533/161533 [==============================] - 19s 115us/step - loss: 14.0604 - val_loss: 14.6246\n","Epoch 7/10\n","161533/161533 [==============================] - 18s 114us/step - loss: 14.0428 - val_loss: 14.4712\n","Epoch 8/10\n","161533/161533 [==============================] - 19s 116us/step - loss: 14.0390 - val_loss: 14.5352\n","Epoch 9/10\n","161533/161533 [==============================] - 19s 115us/step - loss: 14.0194 - val_loss: 14.5394\n","Epoch 10/10\n","161533/161533 [==============================] - 19s 118us/step - loss: 14.0121 - val_loss: 14.4976\n"],"name":"stdout"}]},{"metadata":{"id":"IpQfmIeSGAan","colab_type":"code","outputId":"123e131f-2984-46ef-f8cc-fc8a74ddf936","executionInfo":{"status":"ok","timestamp":1545384998559,"user_tz":-120,"elapsed":3993,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":["toPred_scale_v2 = preprocessing.scale(df_test_v2.iloc[:,6:])\n","\n","pred_nn_v2 = model.predict(toPred_scale_v2)\n","sub = pd.DataFrame(data=df_test_v2.iloc[:,2])\n","sub['target'] = pred_nn_v2\n","sub.to_csv('submission10.csv', encoding='utf-8', index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\"Numerical issues were encountered \"\n"],"name":"stderr"}]},{"metadata":{"id":"Ya4kApj1JIg2","colab_type":"text"},"cell_type":"markdown","source":["simplier nn model"]},{"metadata":{"id":"QB6HD71JGit4","colab_type":"code","outputId":"2823b9b1-6a4e-461f-fcb0-cb7679e730c3","executionInfo":{"status":"ok","timestamp":1545386098181,"user_tz":-120,"elapsed":77923,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":595}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(50, activation='relu', input_shape=(23,)))\n","model.add(Dense(25, activation='relu'))\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adamax')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_44 (Dense)             (None, 50)                1200      \n","_________________________________________________________________\n","dense_45 (Dense)             (None, 25)                1275      \n","_________________________________________________________________\n","dense_46 (Dense)             (None, 1)                 26        \n","=================================================================\n","Total params: 2,501\n","Trainable params: 2,501\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/10\n","161533/161533 [==============================] - 9s 53us/step - loss: 14.3364 - val_loss: 14.6738\n","Epoch 2/10\n","161533/161533 [==============================] - 7s 45us/step - loss: 14.1457 - val_loss: 14.6397\n","Epoch 3/10\n","161533/161533 [==============================] - 7s 45us/step - loss: 14.0894 - val_loss: 14.6192\n","Epoch 4/10\n","161533/161533 [==============================] - 7s 45us/step - loss: 14.0593 - val_loss: 14.5426\n","Epoch 5/10\n","161533/161533 [==============================] - 7s 46us/step - loss: 14.0404 - val_loss: 14.5737\n","Epoch 6/10\n","161533/161533 [==============================] - 7s 45us/step - loss: 14.0231 - val_loss: 14.5162\n","Epoch 7/10\n","161533/161533 [==============================] - 7s 45us/step - loss: 14.0133 - val_loss: 14.5063\n","Epoch 8/10\n","161533/161533 [==============================] - 8s 51us/step - loss: 14.0012 - val_loss: 14.5043\n","Epoch 9/10\n","161533/161533 [==============================] - 9s 55us/step - loss: 13.9893 - val_loss: 14.5152\n","Epoch 10/10\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.9821 - val_loss: 14.4655\n"],"name":"stdout"}]},{"metadata":{"id":"sBQfbvHqJV3v","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"HWdheJGfJVw3","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"cYwUuZP_JVpI","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vOVdRzgWJVOm","colab_type":"text"},"cell_type":"markdown","source":["# Adding more features v3\n","\n","---\n","\n","V3 is combination of train/test & historical & new transactions"]},{"metadata":{"id":"f1C2zOy1Jsf-","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train_v3 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/train_merge_new&H_transactions.csv')\n","df_test_v3 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/test_merge_new&H_transactions.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"N9fce84yNHoC","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train_v3.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n4QiTbwSNHla","colab_type":"code","outputId":"8047565e-f3fd-4499-819f-5343f253349b","executionInfo":{"status":"ok","timestamp":1545403358757,"user_tz":-120,"elapsed":1495,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["X_train = df_train_v3.iloc[:,7:]\n","#X_train = X_train.drop(['target'], axis=1)\n","X_scaled = preprocessing.scale(X_train)\n","X_scaled = pd.DataFrame(data=X_scaled)\n","Y_train = df_train_v3.iloc[:,6]\n","x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y_train, test_size=0.2, random_state=10)\n","\n","\n","#get some ML banchmark to comper \n","clf = Lasso(alpha=0.2)\n","clf.fit(x_train,y_train)\n","\n","clf_pred = clf.predict(x_test)\n","rms = sqrt(mean_squared_error(y_test, clf_pred))\n","print(rms)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\"Numerical issues were encountered \"\n"],"name":"stderr"},{"output_type":"stream","text":["3.7856005548649665\n"],"name":"stdout"}]},{"metadata":{"id":"feLVw8zeNHid","colab_type":"code","outputId":"c97e2b2e-1c8b-4ce8-85b4-2d6d6bd7961d","executionInfo":{"status":"ok","timestamp":1545403576350,"user_tz":-120,"elapsed":194395,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(50, activation='relu', input_shape=(48,)))\n","model.add(Dense(25, activation='relu'))\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=20)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_86 (Dense)             (None, 50)                2450      \n","_________________________________________________________________\n","dense_87 (Dense)             (None, 25)                1275      \n","_________________________________________________________________\n","dense_88 (Dense)             (None, 1)                 26        \n","=================================================================\n","Total params: 3,751\n","Trainable params: 3,751\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/20\n","161533/161533 [==============================] - 12s 74us/step - loss: 14.0332 - val_loss: 14.2389\n","Epoch 2/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.8496 - val_loss: 14.0805\n","Epoch 3/20\n","161533/161533 [==============================] - 9s 59us/step - loss: 13.6830 - val_loss: 14.0906\n","Epoch 4/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.6127 - val_loss: 13.9943\n","Epoch 5/20\n","161533/161533 [==============================] - 10s 59us/step - loss: 13.5774 - val_loss: 14.0469\n","Epoch 6/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.5368 - val_loss: 14.1210\n","Epoch 7/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.4897 - val_loss: 14.0374\n","Epoch 8/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.4534 - val_loss: 13.9787\n","Epoch 9/20\n","161533/161533 [==============================] - 9s 59us/step - loss: 13.4210 - val_loss: 13.9819\n","Epoch 10/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.4019 - val_loss: 14.0154\n","Epoch 11/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.3812 - val_loss: 14.0141\n","Epoch 12/20\n","161533/161533 [==============================] - 11s 67us/step - loss: 13.3448 - val_loss: 14.0037\n","Epoch 13/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.3070 - val_loss: 14.0001\n","Epoch 14/20\n","161533/161533 [==============================] - 9s 59us/step - loss: 13.2801 - val_loss: 14.0349\n","Epoch 15/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.2586 - val_loss: 14.0126\n","Epoch 16/20\n","161533/161533 [==============================] - 10s 63us/step - loss: 13.2293 - val_loss: 14.0519\n","Epoch 17/20\n","161533/161533 [==============================] - 10s 60us/step - loss: 13.2118 - val_loss: 14.1344\n","Epoch 18/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.1654 - val_loss: 14.0436\n","Epoch 19/20\n","161533/161533 [==============================] - 9s 58us/step - loss: 13.1622 - val_loss: 14.0621\n","Epoch 20/20\n","161533/161533 [==============================] - 9s 59us/step - loss: 13.1071 - val_loss: 14.0946\n"],"name":"stdout"}]},{"metadata":{"id":"HLRyY6BrNHVl","colab_type":"code","outputId":"441f9881-5a4e-431b-de45-f5cb0d0ffe0e","executionInfo":{"status":"ok","timestamp":1545388966292,"user_tz":-120,"elapsed":483174,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":1071}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(50, activation='relu', input_shape=(45,)))\n","model.add(Dense(100, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=20)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_75 (Dense)             (None, 50)                2300      \n","_________________________________________________________________\n","dense_76 (Dense)             (None, 100)               5100      \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 100)               400       \n","_________________________________________________________________\n","dense_77 (Dense)             (None, 256)               25856     \n","_________________________________________________________________\n","dense_78 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_79 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 100,729\n","Trainable params: 100,017\n","Non-trainable params: 712\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/20\n","161533/161533 [==============================] - 26s 159us/step - loss: 14.2693 - val_loss: 14.3963\n","Epoch 2/20\n","161533/161533 [==============================] - 23s 145us/step - loss: 13.9458 - val_loss: 14.1219\n","Epoch 3/20\n","161533/161533 [==============================] - 25s 152us/step - loss: 13.8500 - val_loss: 14.2666\n","Epoch 4/20\n","161533/161533 [==============================] - 25s 158us/step - loss: 13.7658 - val_loss: 14.1162\n","Epoch 5/20\n","161533/161533 [==============================] - 23s 144us/step - loss: 13.7504 - val_loss: 14.5922\n","Epoch 6/20\n","161533/161533 [==============================] - 24s 146us/step - loss: 13.7454 - val_loss: 14.2262\n","Epoch 7/20\n","161533/161533 [==============================] - 24s 146us/step - loss: 13.6904 - val_loss: 14.1935\n","Epoch 8/20\n","161533/161533 [==============================] - 23s 145us/step - loss: 13.6740 - val_loss: 14.2646\n","Epoch 9/20\n","161533/161533 [==============================] - 24s 147us/step - loss: 13.6415 - val_loss: 19.6583\n","Epoch 10/20\n","161533/161533 [==============================] - 22s 138us/step - loss: 13.6067 - val_loss: 14.1286\n","Epoch 11/20\n","161533/161533 [==============================] - 24s 149us/step - loss: 13.5799 - val_loss: 14.0584\n","Epoch 12/20\n","161533/161533 [==============================] - 24s 146us/step - loss: 13.5951 - val_loss: 14.2080\n","Epoch 13/20\n","161533/161533 [==============================] - 23s 145us/step - loss: 13.5661 - val_loss: 14.1196\n","Epoch 14/20\n","161533/161533 [==============================] - 25s 153us/step - loss: 13.5279 - val_loss: 14.1521\n","Epoch 15/20\n","161533/161533 [==============================] - 24s 150us/step - loss: 13.5143 - val_loss: 13.9285\n","Epoch 16/20\n","161533/161533 [==============================] - 25s 156us/step - loss: 13.5077 - val_loss: 14.2330\n","Epoch 17/20\n","161533/161533 [==============================] - 26s 159us/step - loss: 13.4880 - val_loss: 14.0835\n","Epoch 18/20\n","161533/161533 [==============================] - 24s 148us/step - loss: 13.4488 - val_loss: 14.1188\n","Epoch 19/20\n","161533/161533 [==============================] - 24s 148us/step - loss: 13.4553 - val_loss: 14.0913\n","Epoch 20/20\n","161533/161533 [==============================] - 23s 144us/step - loss: 13.4177 - val_loss: 14.0897\n"],"name":"stdout"}]},{"metadata":{"id":"92j1SG4-j7r4","colab_type":"text"},"cell_type":"markdown","source":["nn deep model \n","\n","*   got 3.787!!!\n","\n","\n"]},{"metadata":{"id":"N9oTLQVhPhW1","colab_type":"code","outputId":"f13622db-385f-4f65-e225-22982dda1cfe","executionInfo":{"status":"ok","timestamp":1545404361127,"user_tz":-120,"elapsed":760820,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":1139}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(128, activation='relu', input_shape=(48,)))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=20)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_94 (Dense)             (None, 128)               6272      \n","_________________________________________________________________\n","batch_normalization_21 (Batc (None, 128)               512       \n","_________________________________________________________________\n","dense_95 (Dense)             (None, 256)               33024     \n","_________________________________________________________________\n","batch_normalization_22 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_96 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_23 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_97 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_24 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_98 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 174,721\n","Trainable params: 172,929\n","Non-trainable params: 1,792\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/20\n","161533/161533 [==============================] - 41s 256us/step - loss: 14.2963 - val_loss: 14.5473\n","Epoch 2/20\n","161533/161533 [==============================] - 38s 237us/step - loss: 13.9729 - val_loss: 14.3147\n","Epoch 3/20\n","161533/161533 [==============================] - 38s 235us/step - loss: 13.8639 - val_loss: 14.1331\n","Epoch 4/20\n","161533/161533 [==============================] - 37s 227us/step - loss: 13.7851 - val_loss: 14.0785\n","Epoch 5/20\n","161533/161533 [==============================] - 38s 236us/step - loss: 13.7412 - val_loss: 14.1043\n","Epoch 6/20\n","161533/161533 [==============================] - 38s 237us/step - loss: 13.6873 - val_loss: 14.0551\n","Epoch 7/20\n","161533/161533 [==============================] - 38s 232us/step - loss: 13.6333 - val_loss: 14.0223\n","Epoch 8/20\n","161533/161533 [==============================] - 38s 233us/step - loss: 13.6060 - val_loss: 14.1579\n","Epoch 9/20\n","161533/161533 [==============================] - 37s 230us/step - loss: 13.5735 - val_loss: 14.1050\n","Epoch 10/20\n","161533/161533 [==============================] - 37s 232us/step - loss: 13.5471 - val_loss: 14.1460\n","Epoch 11/20\n","161533/161533 [==============================] - 37s 230us/step - loss: 13.5248 - val_loss: 14.1930\n","Epoch 12/20\n","161533/161533 [==============================] - 37s 228us/step - loss: 13.4858 - val_loss: 14.0522\n","Epoch 13/20\n","161533/161533 [==============================] - 38s 235us/step - loss: 13.4576 - val_loss: 14.1083\n","Epoch 14/20\n","161533/161533 [==============================] - 39s 241us/step - loss: 13.4244 - val_loss: 14.0043\n","Epoch 15/20\n","161533/161533 [==============================] - 39s 239us/step - loss: 13.4085 - val_loss: 14.0735\n","Epoch 16/20\n","161533/161533 [==============================] - 38s 237us/step - loss: 13.3825 - val_loss: 14.1007\n","Epoch 17/20\n","161533/161533 [==============================] - 37s 227us/step - loss: 13.3702 - val_loss: 14.1438\n","Epoch 18/20\n","161533/161533 [==============================] - 38s 232us/step - loss: 13.3347 - val_loss: 14.1388\n","Epoch 19/20\n","161533/161533 [==============================] - 39s 240us/step - loss: 13.2935 - val_loss: 15.6333\n","Epoch 20/20\n","161533/161533 [==============================] - 37s 227us/step - loss: 13.2407 - val_loss: 19.5283\n"],"name":"stdout"}]},{"metadata":{"id":"eEQeYW_6QZV9","colab_type":"code","outputId":"d7fd1dc8-628a-4b2d-c97a-6d70b005d2b3","executionInfo":{"status":"ok","timestamp":1545388044190,"user_tz":-120,"elapsed":7537,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":["toPred_scale_v3 = preprocessing.scale(df_test_v3.iloc[:,6:])\n","\n","pred_nn_v3 = model.predict(toPred_scale_v3)\n","sub = pd.DataFrame(data=df_test_v3.iloc[:,2])\n","sub['target'] = pred_nn_v3\n","sub.to_csv('submission11.csv', encoding='utf-8', index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\"Numerical issues were encountered \"\n"],"name":"stderr"}]},{"metadata":{"id":"00xUzZsdglbf","colab_type":"text"},"cell_type":"markdown","source":["# Adding more features V4\n","\n","---\n","\n","now we add one hot encoding for the categorial fetures, based on hist+new transactions "]},{"metadata":{"id":"vjkhZ_o-nUnA","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train_v4 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/V4_train_new+hist+main.csv')\n","df_test_v4 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/V4_test_new+hist+main.csv')\n","df_train_v4 = df_train_v4.fillna(0)\n","df_test_v4 = df_test_v4.fillna(0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZGCaF2MYhtFO","colab_type":"code","outputId":"51b0df98-ed09-46d8-ff92-4700372f6487","executionInfo":{"status":"error","timestamp":1545510561477,"user_tz":-120,"elapsed":907,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":608}},"cell_type":"code","source":["X_train = df_train_v4.iloc[:,2:]\n","X_train = X_train.drop(['target'], axis=1)\n","X_train = X_train.drop(['first_active_month'], axis=1)\n","#X_scaled = preprocessing.scale(X_train)\n","#X_scaled = pd.DataFrame(data=X_scaled)\n","Y_train = df_train_v4.loc[:,'target']\n","x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=10)\n","\n","\n","#get some ML banchmark to comper \n","clf = Lasso(alpha=0.2)\n","clf.fit(x_train,y_train)\n","\n","clf_pred = clf.predict(x_test)\n","rms = sqrt(mean_squared_error(y_test, clf_pred))\n","print(rms)"],"execution_count":102,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-102-08c3bf89f8a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#get some ML banchmark to comper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mclf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    711\u001b[0m             X, y = check_X_y(X, y, accept_sparse='csc',\n\u001b[1;32m    712\u001b[0m                              \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                              copy=X_copied, multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    714\u001b[0m             y = check_array(y, order='F', copy=False, dtype=X.dtype.type,\n\u001b[1;32m    715\u001b[0m                             ensure_2d=False)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 582\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 91)) while a minimum of 1 is required."]}]},{"metadata":{"id":"w1PAfhINhTb-","colab_type":"text"},"cell_type":"markdown","source":["testing our deep nn model over v4 data"]},{"metadata":{"id":"nvhfUwbd-dLr","colab_type":"code","outputId":"94a8ef0c-b7f4-4179-ca69-a969247a2296","executionInfo":{"status":"ok","timestamp":1545437782070,"user_tz":-120,"elapsed":636,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":1969}},"cell_type":"code","source":["df_test_v4.head(3).T"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Unnamed: 0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>card_id</th>\n","      <td>C_ID_0ab67a22ab</td>\n","      <td>C_ID_130fd0cbdd</td>\n","      <td>C_ID_b709037bc5</td>\n","    </tr>\n","    <tr>\n","      <th>elapsed_time</th>\n","      <td>306</td>\n","      <td>396</td>\n","      <td>184</td>\n","    </tr>\n","    <tr>\n","      <th>first_active_month</th>\n","      <td>2017-04-01</td>\n","      <td>2017-01-01</td>\n","      <td>2017-08-01</td>\n","    </tr>\n","    <tr>\n","      <th>hist_authorized_flag_mean</th>\n","      <td>0.647059</td>\n","      <td>0.987179</td>\n","      <td>0.692308</td>\n","    </tr>\n","    <tr>\n","      <th>hist_authorized_flag_sum</th>\n","      <td>44</td>\n","      <td>77</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_1_mean</th>\n","      <td>0.338235</td>\n","      <td>0.025641</td>\n","      <td>0.0769231</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_1_sum</th>\n","      <td>23</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_1_mean</th>\n","      <td>0.661765</td>\n","      <td>0</td>\n","      <td>0.0769231</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_1_sum</th>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_2_mean</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_2_sum</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_3_mean</th>\n","      <td>0</td>\n","      <td>0.0128205</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_3_sum</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_4_mean</th>\n","      <td>0</td>\n","      <td>0.961538</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_4_sum</th>\n","      <td>0</td>\n","      <td>75</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_5_mean</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.846154</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_5_sum</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_nunique</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_3_A_sum</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_3_B_sum</th>\n","      <td>46</td>\n","      <td>76</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_3_C_sum</th>\n","      <td>22</td>\n","      <td>2</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>hist_city_id_nunique</th>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_max</th>\n","      <td>12</td>\n","      <td>4</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_median</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_min</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_std</th>\n","      <td>2.06113</td>\n","      <td>0.405794</td>\n","      <td>3.68643</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_sum</th>\n","      <td>141</td>\n","      <td>83</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>hist_merchant_category_id_nunique</th>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>hist_merchant_id_nunique</th>\n","      <td>24</td>\n","      <td>27</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>new_installments_std</th>\n","      <td>1.1547</td>\n","      <td>0.666667</td>\n","      <td>6.36396</td>\n","    </tr>\n","    <tr>\n","      <th>new_installments_sum</th>\n","      <td>5</td>\n","      <td>11</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>new_merchant_category_id_nunique</th>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>new_merchant_id_nunique</th>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>new_month_lag_max</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>new_month_lag_min</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_max</th>\n","      <td>-0.3833</td>\n","      <td>-0.5063</td>\n","      <td>0.9043</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_median</th>\n","      <td>-0.672</td>\n","      <td>-0.6567</td>\n","      <td>0.08984</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_min</th>\n","      <td>-0.722</td>\n","      <td>-0.7407</td>\n","      <td>-0.7246</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_std</th>\n","      <td>0.1829</td>\n","      <td>0.07117</td>\n","      <td>1.152</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_sum</th>\n","      <td>-1.777</td>\n","      <td>-5.945</td>\n","      <td>0.1797</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_date_max</th>\n","      <td>1.52</td>\n","      <td>1.524</td>\n","      <td>1.5205</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_date_min</th>\n","      <td>1.518</td>\n","      <td>1.5205</td>\n","      <td>1.52</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_date_ptp</th>\n","      <td>0.001953</td>\n","      <td>0.003906</td>\n","      <td>0.000977</td>\n","    </tr>\n","    <tr>\n","      <th>new_state_id_nunique</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>new_subsector_id_nunique</th>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>new_transactions_count</th>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>start_month</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>start_year</th>\n","      <td>2017</td>\n","      <td>2017</td>\n","      <td>2017</td>\n","    </tr>\n","    <tr>\n","      <th>target</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>feature_2_0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>feature_2_1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_2_2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_3_0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_3_1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>95 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                 0                1  \\\n","Unnamed: 0                                       0                1   \n","card_id                            C_ID_0ab67a22ab  C_ID_130fd0cbdd   \n","elapsed_time                                   306              396   \n","first_active_month                      2017-04-01       2017-01-01   \n","hist_authorized_flag_mean                 0.647059         0.987179   \n","hist_authorized_flag_sum                        44               77   \n","hist_category_1_mean                      0.338235         0.025641   \n","hist_category_1_sum                             23                2   \n","hist_category_2_1_mean                    0.661765                0   \n","hist_category_2_1_sum                           45                0   \n","hist_category_2_2_mean                           0                0   \n","hist_category_2_2_sum                            0                0   \n","hist_category_2_3_mean                           0        0.0128205   \n","hist_category_2_3_sum                            0                1   \n","hist_category_2_4_mean                           0         0.961538   \n","hist_category_2_4_sum                            0               75   \n","hist_category_2_5_mean                           0                0   \n","hist_category_2_5_sum                            0                0   \n","hist_category_2_nunique                          1                2   \n","hist_category_3_A_sum                            0                0   \n","hist_category_3_B_sum                           46               76   \n","hist_category_3_C_sum                           22                2   \n","hist_city_id_nunique                             7                4   \n","hist_installments_max                           12                4   \n","hist_installments_median                         1                1   \n","hist_installments_min                            1                1   \n","hist_installments_std                      2.06113         0.405794   \n","hist_installments_sum                          141               83   \n","hist_merchant_category_id_nunique               16               16   \n","hist_merchant_id_nunique                        24               27   \n","...                                            ...              ...   \n","new_installments_std                        1.1547         0.666667   \n","new_installments_sum                             5               11   \n","new_merchant_category_id_nunique                 3                8   \n","new_merchant_id_nunique                          3                9   \n","new_month_lag_max                                2                2   \n","new_month_lag_min                                2                1   \n","new_purchase_amount_max                    -0.3833          -0.5063   \n","new_purchase_amount_median                  -0.672          -0.6567   \n","new_purchase_amount_min                     -0.722          -0.7407   \n","new_purchase_amount_std                     0.1829          0.07117   \n","new_purchase_amount_sum                     -1.777           -5.945   \n","new_purchase_date_max                         1.52            1.524   \n","new_purchase_date_min                        1.518           1.5205   \n","new_purchase_date_ptp                     0.001953         0.003906   \n","new_state_id_nunique                             1                2   \n","new_subsector_id_nunique                         3                6   \n","new_transactions_count                           3                9   \n","start_month                                      4                1   \n","start_year                                    2017             2017   \n","target                                           0                0   \n","feature_1_0                                      0                0   \n","feature_1_1                                      0                1   \n","feature_1_2                                      1                0   \n","feature_1_3                                      0                0   \n","feature_1_4                                      0                0   \n","feature_2_0                                      0                0   \n","feature_2_1                                      0                0   \n","feature_2_2                                      1                1   \n","feature_3_0                                      0                1   \n","feature_3_1                                      1                0   \n","\n","                                                 2  \n","Unnamed: 0                                       2  \n","card_id                            C_ID_b709037bc5  \n","elapsed_time                                   184  \n","first_active_month                      2017-08-01  \n","hist_authorized_flag_mean                 0.692308  \n","hist_authorized_flag_sum                         9  \n","hist_category_1_mean                     0.0769231  \n","hist_category_1_sum                              1  \n","hist_category_2_1_mean                   0.0769231  \n","hist_category_2_1_sum                            1  \n","hist_category_2_2_mean                           0  \n","hist_category_2_2_sum                            0  \n","hist_category_2_3_mean                           0  \n","hist_category_2_3_sum                            0  \n","hist_category_2_4_mean                           0  \n","hist_category_2_4_sum                            0  \n","hist_category_2_5_mean                    0.846154  \n","hist_category_2_5_sum                           11  \n","hist_category_2_nunique                          2  \n","hist_category_3_A_sum                            0  \n","hist_category_3_B_sum                            1  \n","hist_category_3_C_sum                            9  \n","hist_city_id_nunique                             4  \n","hist_installments_max                           10  \n","hist_installments_median                         4  \n","hist_installments_min                           -1  \n","hist_installments_std                      3.68643  \n","hist_installments_sum                           44  \n","hist_merchant_category_id_nunique                8  \n","hist_merchant_id_nunique                         9  \n","...                                            ...  \n","new_installments_std                       6.36396  \n","new_installments_sum                            11  \n","new_merchant_category_id_nunique                 2  \n","new_merchant_id_nunique                          2  \n","new_month_lag_max                                1  \n","new_month_lag_min                                1  \n","new_purchase_amount_max                     0.9043  \n","new_purchase_amount_median                 0.08984  \n","new_purchase_amount_min                    -0.7246  \n","new_purchase_amount_std                      1.152  \n","new_purchase_amount_sum                     0.1797  \n","new_purchase_date_max                       1.5205  \n","new_purchase_date_min                         1.52  \n","new_purchase_date_ptp                     0.000977  \n","new_state_id_nunique                             2  \n","new_subsector_id_nunique                         2  \n","new_transactions_count                           2  \n","start_month                                      8  \n","start_year                                    2017  \n","target                                           0  \n","feature_1_0                                      0  \n","feature_1_1                                      0  \n","feature_1_2                                      0  \n","feature_1_3                                      0  \n","feature_1_4                                      1  \n","feature_2_0                                      1  \n","feature_2_1                                      0  \n","feature_2_2                                      0  \n","feature_3_0                                      0  \n","feature_3_1                                      1  \n","\n","[95 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":79}]},{"metadata":{"id":"6JRBtjIpTQcG","colab_type":"text"},"cell_type":"markdown","source":["deep nn model over v4 data\n","*   got 3.778\n","\n","\n"]},{"metadata":{"id":"7o3K_0qohQxo","colab_type":"code","outputId":"9da4ce15-92b6-4ca7-dd6a-b4ba283e2bd9","executionInfo":{"status":"ok","timestamp":1545485023170,"user_tz":-120,"elapsed":307885,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":799}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(128, activation='relu', input_shape=(91,)))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=10)\n"],"execution_count":45,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 128)               11776     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 128)               512       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               33024     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 180,225\n","Trainable params: 178,433\n","Non-trainable params: 1,792\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/10\n","161533/161533 [==============================] - 32s 199us/step - loss: 14.5816 - val_loss: 68.6316\n","Epoch 2/10\n","161533/161533 [==============================] - 30s 188us/step - loss: 14.5132 - val_loss: 40.6955\n","Epoch 3/10\n","161533/161533 [==============================] - 31s 194us/step - loss: 14.4867 - val_loss: 17.0163\n","Epoch 4/10\n","161533/161533 [==============================] - 30s 185us/step - loss: 14.4766 - val_loss: 15.4917\n","Epoch 5/10\n","161533/161533 [==============================] - 30s 188us/step - loss: 14.4609 - val_loss: 15.3362\n","Epoch 6/10\n","161533/161533 [==============================] - 31s 189us/step - loss: 14.4383 - val_loss: 22.7269\n","Epoch 7/10\n","161533/161533 [==============================] - 30s 188us/step - loss: 14.4300 - val_loss: 15.4134\n","Epoch 8/10\n","161533/161533 [==============================] - 30s 185us/step - loss: 14.4191 - val_loss: 16.9783\n","Epoch 9/10\n","161533/161533 [==============================] - 30s 186us/step - loss: 14.4202 - val_loss: 15.8973\n","Epoch 10/10\n","161533/161533 [==============================] - 30s 186us/step - loss: 14.4084 - val_loss: 15.6213\n"],"name":"stdout"}]},{"metadata":{"id":"DQkUXJc5QH0O","colab_type":"code","outputId":"ed1318c9-034f-4fab-806d-99651915569c","executionInfo":{"status":"ok","timestamp":1545437506539,"user_tz":-120,"elapsed":820,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":191}},"cell_type":"code","source":["Xpred=df_test_v4.iloc[:,2:]\n","Xpred.head(3)\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>elapsed_time</th>\n","      <th>first_active_month</th>\n","      <th>hist_authorized_flag_mean</th>\n","      <th>hist_authorized_flag_sum</th>\n","      <th>hist_category_1_mean</th>\n","      <th>hist_category_1_sum</th>\n","      <th>hist_category_2_1_mean</th>\n","      <th>hist_category_2_1_sum</th>\n","      <th>hist_category_2_2_mean</th>\n","      <th>hist_category_2_2_sum</th>\n","      <th>...</th>\n","      <th>feature_1_0</th>\n","      <th>feature_1_1</th>\n","      <th>feature_1_2</th>\n","      <th>feature_1_3</th>\n","      <th>feature_1_4</th>\n","      <th>feature_2_0</th>\n","      <th>feature_2_1</th>\n","      <th>feature_2_2</th>\n","      <th>feature_3_0</th>\n","      <th>feature_3_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>306.0</td>\n","      <td>2017-04-01</td>\n","      <td>0.647059</td>\n","      <td>44.0</td>\n","      <td>0.338235</td>\n","      <td>23.0</td>\n","      <td>0.661765</td>\n","      <td>45.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>396.0</td>\n","      <td>2017-01-01</td>\n","      <td>0.987179</td>\n","      <td>77.0</td>\n","      <td>0.025641</td>\n","      <td>2.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>184.0</td>\n","      <td>2017-08-01</td>\n","      <td>0.692308</td>\n","      <td>9.0</td>\n","      <td>0.076923</td>\n","      <td>1.0</td>\n","      <td>0.076923</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 93 columns</p>\n","</div>"],"text/plain":["   elapsed_time first_active_month  hist_authorized_flag_mean  \\\n","0         306.0         2017-04-01                   0.647059   \n","1         396.0         2017-01-01                   0.987179   \n","2         184.0         2017-08-01                   0.692308   \n","\n","   hist_authorized_flag_sum  hist_category_1_mean  hist_category_1_sum  \\\n","0                      44.0              0.338235                 23.0   \n","1                      77.0              0.025641                  2.0   \n","2                       9.0              0.076923                  1.0   \n","\n","   hist_category_2_1_mean  hist_category_2_1_sum  hist_category_2_2_mean  \\\n","0                0.661765                   45.0                     0.0   \n","1                0.000000                    0.0                     0.0   \n","2                0.076923                    1.0                     0.0   \n","\n","   hist_category_2_2_sum     ...       feature_1_0  feature_1_1  feature_1_2  \\\n","0                    0.0     ...                 0            0            1   \n","1                    0.0     ...                 0            1            0   \n","2                    0.0     ...                 0            0            0   \n","\n","   feature_1_3  feature_1_4  feature_2_0  feature_2_1  feature_2_2  \\\n","0            0            0            0            0            1   \n","1            0            0            0            0            1   \n","2            0            1            1            0            0   \n","\n","   feature_3_0  feature_3_1  \n","0            0            1  \n","1            1            0  \n","2            0            1  \n","\n","[3 rows x 93 columns]"]},"metadata":{"tags":[]},"execution_count":71}]},{"metadata":{"id":"0hGpcnRF8-Hz","colab_type":"code","outputId":"75eb51f1-d64b-4d1b-dcb3-c8eff9fcb4d0","executionInfo":{"status":"ok","timestamp":1545437871096,"user_tz":-120,"elapsed":9359,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":["Xpred=df_test_v4.iloc[:,2:]\n","Xpred = Xpred.drop(['first_active_month'], axis=1)\n","Xpred = Xpred.drop(['target'], axis=1)\n","toPred_scale_v4 = preprocessing.scale(Xpred)\n","\n","pred_nn_v4 = model.predict(toPred_scale_v4)\n","sub = pd.DataFrame(data=df_test_v4.iloc[:,1])\n","sub['target'] = pred_nn_v4\n","sub.to_csv('submission12.csv', encoding='utf-8', index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\"Numerical issues were encountered \"\n"],"name":"stderr"}]},{"metadata":{"id":"2tbKQHCMP6wy","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"RjCDaAG0hh0m","colab_type":"code","outputId":"b503b53d-2ab5-4eac-d89d-c546e0c1511f","executionInfo":{"status":"ok","timestamp":1545432708673,"user_tz":-120,"elapsed":216917,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":697}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(91, activation='relu', input_shape=(91,)))\n","model.add(BatchNormalization())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_23 (Dense)             (None, 91)                8372      \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 91)                364       \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 256)               23552     \n","_________________________________________________________________\n","dense_25 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_26 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 99,361\n","Trainable params: 98,667\n","Non-trainable params: 694\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/10\n","161533/161533 [==============================] - 23s 140us/step - loss: 14.2706 - val_loss: 14.5918\n","Epoch 2/10\n","161533/161533 [==============================] - 21s 132us/step - loss: 13.8661 - val_loss: 14.2264\n","Epoch 3/10\n","161533/161533 [==============================] - 21s 133us/step - loss: 13.7422 - val_loss: 14.4196\n","Epoch 4/10\n","161533/161533 [==============================] - 22s 135us/step - loss: 13.6888 - val_loss: 14.0769\n","Epoch 5/10\n","161533/161533 [==============================] - 21s 131us/step - loss: 13.6154 - val_loss: 14.0918\n","Epoch 6/10\n","161533/161533 [==============================] - 21s 133us/step - loss: 13.5449 - val_loss: 14.2120\n","Epoch 7/10\n","161533/161533 [==============================] - 22s 134us/step - loss: 13.4740 - val_loss: 14.0573\n","Epoch 8/10\n","161533/161533 [==============================] - 21s 131us/step - loss: 13.4091 - val_loss: 14.1080\n","Epoch 9/10\n","161533/161533 [==============================] - 21s 130us/step - loss: 13.3445 - val_loss: 14.0907\n","Epoch 10/10\n","161533/161533 [==============================] - 21s 131us/step - loss: 13.3116 - val_loss: 14.2101\n"],"name":"stdout"}]},{"metadata":{"id":"yC4YfZ46hhxn","colab_type":"code","outputId":"5c9c9d93-af43-4de6-9abe-4a2acf1143d6","executionInfo":{"status":"ok","timestamp":1545431424192,"user_tz":-120,"elapsed":152235,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(50, activation='relu', input_shape=(91,)))\n","model.add(Dense(25, activation='relu'))\n","model.add(Dense(1, activation='linear'))\n","  \n","model.compile(loss='mse', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,validation_split=0.2,shuffle=True,epochs=20)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_11 (Dense)             (None, 50)                4600      \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 25)                1275      \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1)                 26        \n","=================================================================\n","Total params: 5,901\n","Trainable params: 5,901\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 161533 samples, validate on 40384 samples\n","Epoch 1/20\n","161533/161533 [==============================] - 8s 51us/step - loss: 14.0995 - val_loss: 14.3165\n","Epoch 2/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.7305 - val_loss: 14.1784\n","Epoch 3/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.6048 - val_loss: 14.2221\n","Epoch 4/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.5159 - val_loss: 14.1656\n","Epoch 5/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.4247 - val_loss: 14.1517\n","Epoch 6/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.3573 - val_loss: 14.0869\n","Epoch 7/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.3123 - val_loss: 14.0135\n","Epoch 8/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.2436 - val_loss: 14.0245\n","Epoch 9/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.1807 - val_loss: 14.0361\n","Epoch 10/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.1179 - val_loss: 14.0264\n","Epoch 11/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 13.0234 - val_loss: 14.0180\n","Epoch 12/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 12.9655 - val_loss: 14.0893\n","Epoch 13/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 12.9160 - val_loss: 14.1720\n","Epoch 14/20\n","161533/161533 [==============================] - 8s 53us/step - loss: 12.8267 - val_loss: 14.2086\n","Epoch 15/20\n","161533/161533 [==============================] - 8s 48us/step - loss: 12.7443 - val_loss: 14.1758\n","Epoch 16/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 12.6807 - val_loss: 14.2641\n","Epoch 17/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 12.5823 - val_loss: 14.2132\n","Epoch 18/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 12.5503 - val_loss: 14.4836\n","Epoch 19/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 12.4530 - val_loss: 14.4174\n","Epoch 20/20\n","161533/161533 [==============================] - 7s 46us/step - loss: 12.3935 - val_loss: 14.5276\n"],"name":"stdout"}]},{"metadata":{"id":"1AxCU5yEr3YY","colab_type":"text"},"cell_type":"markdown","source":["another try now with lgb model\n"]},{"metadata":{"id":"4IxnQYfFvp4d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1969},"outputId":"328aa2ee-a467-4468-d3c9-de9af903d5cf","executionInfo":{"status":"ok","timestamp":1545479352770,"user_tz":-120,"elapsed":634,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}}},"cell_type":"code","source":["xtrain.head(3).T\n"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Unnamed: 0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>elapsed_time</th>\n","      <td>245</td>\n","      <td>396</td>\n","      <td>549</td>\n","    </tr>\n","    <tr>\n","      <th>first_active_month</th>\n","      <td>2017-06-01</td>\n","      <td>2017-01-01</td>\n","      <td>2016-08-01</td>\n","    </tr>\n","    <tr>\n","      <th>hist_authorized_flag_mean</th>\n","      <td>0.95</td>\n","      <td>0.968571</td>\n","      <td>0.953488</td>\n","    </tr>\n","    <tr>\n","      <th>hist_authorized_flag_sum</th>\n","      <td>247</td>\n","      <td>339</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_1_mean</th>\n","      <td>0</td>\n","      <td>0.0885714</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_1_sum</th>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_1_mean</th>\n","      <td>0.988462</td>\n","      <td>0.911429</td>\n","      <td>0.0930233</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_1_sum</th>\n","      <td>257</td>\n","      <td>319</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_2_mean</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_2_sum</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_3_mean</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_3_sum</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_4_mean</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_4_sum</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_5_mean</th>\n","      <td>0.0115385</td>\n","      <td>0</td>\n","      <td>0.906977</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_5_sum</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_2_nunique</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_3_A_sum</th>\n","      <td>256</td>\n","      <td>0</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_3_B_sum</th>\n","      <td>4</td>\n","      <td>276</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_category_3_C_sum</th>\n","      <td>0</td>\n","      <td>72</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_city_id_nunique</th>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_max</th>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_median</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_min</th>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_std</th>\n","      <td>0.123314</td>\n","      <td>1.51078</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_installments_sum</th>\n","      <td>4</td>\n","      <td>543</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hist_merchant_category_id_nunique</th>\n","      <td>41</td>\n","      <td>57</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>hist_merchant_id_nunique</th>\n","      <td>94</td>\n","      <td>142</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>hist_month_lag_max</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>new_installments_std</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>new_installments_sum</th>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>new_merchant_category_id_nunique</th>\n","      <td>14</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>new_merchant_id_nunique</th>\n","      <td>23</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>new_month_lag_max</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>new_month_lag_min</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_max</th>\n","      <td>-0.2961</td>\n","      <td>-0.7017</td>\n","      <td>-0.7</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_median</th>\n","      <td>-0.581</td>\n","      <td>-0.7324</td>\n","      <td>-0.7</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_min</th>\n","      <td>-0.7246</td>\n","      <td>-0.7393</td>\n","      <td>-0.7</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_std</th>\n","      <td>0.1357</td>\n","      <td>0.01438</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_amount_sum</th>\n","      <td>-13.24</td>\n","      <td>-4.355</td>\n","      <td>-0.7</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_date_max</th>\n","      <td>1.525</td>\n","      <td>1.522</td>\n","      <td>1.525</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_date_min</th>\n","      <td>1.5205</td>\n","      <td>1.518</td>\n","      <td>1.525</td>\n","    </tr>\n","    <tr>\n","      <th>new_purchase_date_ptp</th>\n","      <td>0.004883</td>\n","      <td>0.004883</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>new_state_id_nunique</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>new_subsector_id_nunique</th>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>new_transactions_count</th>\n","      <td>23</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>start_month</th>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>start_year</th>\n","      <td>2017</td>\n","      <td>2017</td>\n","      <td>2016</td>\n","    </tr>\n","    <tr>\n","      <th>target</th>\n","      <td>-0.820283</td>\n","      <td>0.392913</td>\n","      <td>0.688056</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_1_4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_2_0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_2_1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>feature_2_2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>feature_3_0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>feature_3_1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>94 rows × 3 columns</p>\n","</div>"],"text/plain":["                                            0           1           2\n","Unnamed: 0                                  0           1           2\n","elapsed_time                              245         396         549\n","first_active_month                 2017-06-01  2017-01-01  2016-08-01\n","hist_authorized_flag_mean                0.95    0.968571    0.953488\n","hist_authorized_flag_sum                  247         339          41\n","hist_category_1_mean                        0   0.0885714           0\n","hist_category_1_sum                         0          31           0\n","hist_category_2_1_mean               0.988462    0.911429   0.0930233\n","hist_category_2_1_sum                     257         319           4\n","hist_category_2_2_mean                      0           0           0\n","hist_category_2_2_sum                       0           0           0\n","hist_category_2_3_mean                      0           0           0\n","hist_category_2_3_sum                       0           0           0\n","hist_category_2_4_mean                      0           0           0\n","hist_category_2_4_sum                       0           0           0\n","hist_category_2_5_mean              0.0115385           0    0.906977\n","hist_category_2_5_sum                       3           0          39\n","hist_category_2_nunique                     2           1           2\n","hist_category_3_A_sum                     256           0          43\n","hist_category_3_B_sum                       4         276           0\n","hist_category_3_C_sum                       0          72           0\n","hist_city_id_nunique                        7           9           5\n","hist_installments_max                       1          10           0\n","hist_installments_median                    0           1           0\n","hist_installments_min                       0          -1           0\n","hist_installments_std                0.123314     1.51078           0\n","hist_installments_sum                       4         543           0\n","hist_merchant_category_id_nunique          41          57           8\n","hist_merchant_id_nunique                   94         142          13\n","hist_month_lag_max                          0           0           0\n","...                                       ...         ...         ...\n","new_installments_std                        0           0           0\n","new_installments_sum                        0           6           0\n","new_merchant_category_id_nunique           14           5           1\n","new_merchant_id_nunique                    23           6           1\n","new_month_lag_max                           2           2           2\n","new_month_lag_min                           1           1           2\n","new_purchase_amount_max               -0.2961     -0.7017        -0.7\n","new_purchase_amount_median             -0.581     -0.7324        -0.7\n","new_purchase_amount_min               -0.7246     -0.7393        -0.7\n","new_purchase_amount_std                0.1357     0.01438           0\n","new_purchase_amount_sum                -13.24      -4.355        -0.7\n","new_purchase_date_max                   1.525       1.522       1.525\n","new_purchase_date_min                  1.5205       1.518       1.525\n","new_purchase_date_ptp                0.004883    0.004883           0\n","new_state_id_nunique                        1           1           1\n","new_subsector_id_nunique                   10           4           1\n","new_transactions_count                     23           6           1\n","start_month                                 6           1           8\n","start_year                               2017        2017        2016\n","target                              -0.820283    0.392913    0.688056\n","feature_1_0                                 0           0           0\n","feature_1_1                                 0           0           1\n","feature_1_2                                 0           0           0\n","feature_1_3                                 0           1           0\n","feature_1_4                                 1           0           0\n","feature_2_0                                 0           1           0\n","feature_2_1                                 1           0           1\n","feature_2_2                                 0           0           0\n","feature_3_0                                 0           1           1\n","feature_3_1                                 1           0           0\n","\n","[94 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"_78OI6ZYr2_e","colab_type":"code","colab":{}},"cell_type":"code","source":["xtrain = df_train_v4\n","xtrain = xtrain.drop('first_active_month', axis=1)\n","ytrain = df_train_v4['target']\n","xtrain = xtrain.drop('target',axis=1)\n","xtest = df_test_v4\n","# prepare for modeling\n","id_train = xtrain['card_id'].copy(); xtrain.drop('card_id', axis = 1, inplace = True)\n","id_test = xtest['card_id'].copy(); xtest.drop('card_id', axis = 1, inplace = True)\n","\n","\n","nfolds = 10\n","folds = KFold(n_splits= nfolds, shuffle=True, random_state=15)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TLi-0fDdyRod","colab_type":"code","colab":{}},"cell_type":"code","source":["xtrain = xtrain.iloc[:,1:]\n","xtest = xtest.drop('target',axis=1)\n","xtest = xtest.drop('first_active_month',axis=1)\n","xtest = xtest.iloc[:,1:]\n","xtrain = xtrain.fillna(0)\n","xtest = xtest.fillna(0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AHObcBUpr24Y","colab_type":"code","colab":{}},"cell_type":"code","source":["param = {'num_leaves': 50,\n","         'min_data_in_leaf': 30, \n","         'objective':'regression',\n","         'max_depth': 10,\n","         'learning_rate': 0.005,\n","         \"min_child_samples\": 100,\n","         \"boosting\": \"gbdt\",\n","         \"feature_fraction\": 0.9,\n","         \"bagging_freq\": 1,\n","         \"bagging_fraction\": 0.9 ,\n","         \"bagging_seed\": 11,\n","         \"metric\": 'rmse',\n","         \"lambda_l1\": 0.1,\n","         \"verbosity\": -1}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YQgBLxIbtziH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1479},"outputId":"58113c75-c57b-4bd6-b149-6e34dc0f1f3f","executionInfo":{"status":"ok","timestamp":1545484313521,"user_tz":-120,"elapsed":1731841,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}}},"cell_type":"code","source":["feature_importance_df = np.zeros((xtrain.shape[1], nfolds))\n","mvalid = np.zeros(len(xtrain))\n","mfull = np.zeros(len(xtest))\n","\n","\n","start = time.time()\n","\n","for fold_, (trn_idx, val_idx) in enumerate(folds.split(xtrain.values, ytrain.values)):\n","    print('----')\n","    print(\"fold n°{}\".format(fold_))\n","    \n","    x0,y0 = xtrain.iloc[trn_idx], ytrain[trn_idx]\n","    x1,y1 = xtrain.iloc[val_idx], ytrain[val_idx]\n","    \n","    trn_data = lgb.Dataset(x0, label= y0); val_data = lgb.Dataset(x1, label= y1)\n","    \n","    num_round = 10000\n","    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], \n","                    verbose_eval=500, early_stopping_rounds = 150)\n","    mvalid[val_idx] = clf.predict(x1, num_iteration=clf.best_iteration)\n","    \n","    feature_importance_df[:, fold_] = clf.feature_importance()\n","    \n","    mfull += clf.predict(xtest, num_iteration=clf.best_iteration) / folds.n_splits"],"execution_count":39,"outputs":[{"output_type":"stream","text":["----\n","fold n°0\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.56105\tvalid_1's rmse: 3.74187\n","[1000]\ttraining's rmse: 3.47997\tvalid_1's rmse: 3.72519\n","[1500]\ttraining's rmse: 3.42199\tvalid_1's rmse: 3.72132\n","[2000]\ttraining's rmse: 3.37389\tvalid_1's rmse: 3.72049\n","Early stopping, best iteration is:\n","[1880]\ttraining's rmse: 3.38491\tvalid_1's rmse: 3.72024\n","----\n","fold n°1\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.56997\tvalid_1's rmse: 3.67716\n","[1000]\ttraining's rmse: 3.48891\tvalid_1's rmse: 3.66438\n","[1500]\ttraining's rmse: 3.4294\tvalid_1's rmse: 3.66114\n","Early stopping, best iteration is:\n","[1527]\ttraining's rmse: 3.42648\tvalid_1's rmse: 3.66107\n","----\n","fold n°2\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.57331\tvalid_1's rmse: 3.61555\n","[1000]\ttraining's rmse: 3.49169\tvalid_1's rmse: 3.60058\n","[1500]\ttraining's rmse: 3.43217\tvalid_1's rmse: 3.59664\n","[2000]\ttraining's rmse: 3.38366\tvalid_1's rmse: 3.5959\n","Early stopping, best iteration is:\n","[1870]\ttraining's rmse: 3.39556\tvalid_1's rmse: 3.59563\n","----\n","fold n°3\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.56743\tvalid_1's rmse: 3.68695\n","[1000]\ttraining's rmse: 3.48614\tvalid_1's rmse: 3.67675\n","[1500]\ttraining's rmse: 3.42743\tvalid_1's rmse: 3.67402\n","Early stopping, best iteration is:\n","[1589]\ttraining's rmse: 3.41838\tvalid_1's rmse: 3.67362\n","----\n","fold n°4\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.58407\tvalid_1's rmse: 3.52724\n","[1000]\ttraining's rmse: 3.50219\tvalid_1's rmse: 3.51459\n","[1500]\ttraining's rmse: 3.44297\tvalid_1's rmse: 3.51031\n","[2000]\ttraining's rmse: 3.39443\tvalid_1's rmse: 3.50825\n","Early stopping, best iteration is:\n","[2189]\ttraining's rmse: 3.3775\tvalid_1's rmse: 3.50769\n","----\n","fold n°5\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.56639\tvalid_1's rmse: 3.71191\n","[1000]\ttraining's rmse: 3.48586\tvalid_1's rmse: 3.69508\n","[1500]\ttraining's rmse: 3.42758\tvalid_1's rmse: 3.69041\n","[2000]\ttraining's rmse: 3.37912\tvalid_1's rmse: 3.68856\n","[2500]\ttraining's rmse: 3.33563\tvalid_1's rmse: 3.68755\n","Early stopping, best iteration is:\n","[2778]\ttraining's rmse: 3.31318\tvalid_1's rmse: 3.68683\n","----\n","fold n°6\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.54593\tvalid_1's rmse: 3.85445\n","[1000]\ttraining's rmse: 3.46404\tvalid_1's rmse: 3.84324\n","Early stopping, best iteration is:\n","[1241]\ttraining's rmse: 3.43319\tvalid_1's rmse: 3.84107\n","----\n","fold n°7\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.55958\tvalid_1's rmse: 3.76347\n","[1000]\ttraining's rmse: 3.47931\tvalid_1's rmse: 3.74836\n","[1500]\ttraining's rmse: 3.42066\tvalid_1's rmse: 3.74429\n","[2000]\ttraining's rmse: 3.37244\tvalid_1's rmse: 3.74206\n","[2500]\ttraining's rmse: 3.33016\tvalid_1's rmse: 3.74098\n","Early stopping, best iteration is:\n","[2566]\ttraining's rmse: 3.32495\tvalid_1's rmse: 3.74058\n","----\n","fold n°8\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.56619\tvalid_1's rmse: 3.68412\n","[1000]\ttraining's rmse: 3.48579\tvalid_1's rmse: 3.67283\n","[1500]\ttraining's rmse: 3.4271\tvalid_1's rmse: 3.67089\n","Early stopping, best iteration is:\n","[1586]\ttraining's rmse: 3.4188\tvalid_1's rmse: 3.67069\n","----\n","fold n°9\n","Training until validation scores don't improve for 150 rounds.\n","[500]\ttraining's rmse: 3.575\tvalid_1's rmse: 3.61286\n","[1000]\ttraining's rmse: 3.49322\tvalid_1's rmse: 3.59905\n","[1500]\ttraining's rmse: 3.43546\tvalid_1's rmse: 3.59453\n","Early stopping, best iteration is:\n","[1628]\ttraining's rmse: 3.42282\tvalid_1's rmse: 3.59424\n"],"name":"stdout"}]},{"metadata":{"id":"_boBZrG48Nvk","colab_type":"text"},"cell_type":"markdown","source":["lgbm got 3.722!!"]},{"metadata":{"id":"goK5ztgHtzOW","colab_type":"code","colab":{}},"cell_type":"code","source":["xsub = pd.DataFrame()\n","xsub['card_id']  = id_test\n","xsub['target'] = mfull\n","xsub.to_csv('submission14.csv', encoding='utf-8', index=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x4C0AkWN1bRu","colab_type":"text"},"cell_type":"markdown","source":["# Outlier clasification\n","\n","---\n","\n","here we try new direction to classify outlier and than use different regression for each cluster norm/outlier\n"]},{"metadata":{"id":"buVYxvQ55wNt","colab_type":"text"},"cell_type":"markdown","source":["first we need to label the data: 1-outlier 0-normal"]},{"metadata":{"id":"1BzY26kK2uNt","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train_v3 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/train_merge_new&H_transactions.csv')\n","df_test_v3 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/project_2/test_merge_new&H_transactions.csv')\n","\n","X_train = df_train_v3.iloc[:,7:]\n","\n","X_train['outliers_target'] = 0\n","X_train.loc[df_train_v3['target'] < -30, 'outliers_target'] = 1\n","X_train['outliers_target'].value_counts()\n","\n","outliers = X_train.loc[X_train['outliers_target'] == 1]\n","norm = X_train.loc[X_train['outliers_target'] == 0]\n","\n","balanced = norm.sample(n=10000)\n","balanced = balanced.append(outliers)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YUqSEc0cBBmx","colab_type":"code","outputId":"ce0c8a80-4207-4959-ab21-e72cbd6cd5fe","executionInfo":{"status":"ok","timestamp":1545468846693,"user_tz":-120,"elapsed":690,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":191}},"cell_type":"code","source":["balanced.head(3)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>elapsed_time</th>\n","      <th>hist_transactions_count</th>\n","      <th>hist_authorized_flag_sum</th>\n","      <th>hist_authorized_flag_mean</th>\n","      <th>hist_purchase_amount_sum</th>\n","      <th>hist_purchase_amount_mean</th>\n","      <th>hist_purchase_amount_max</th>\n","      <th>hist_purchase_amount_min</th>\n","      <th>hist_purchase_amount_std</th>\n","      <th>hist_installments_sum</th>\n","      <th>...</th>\n","      <th>new_installments_std</th>\n","      <th>new_purchase_month_mean</th>\n","      <th>new_purchase_month_max</th>\n","      <th>new_purchase_month_min</th>\n","      <th>new_purchase_month_std</th>\n","      <th>new_purchase_date_ptp</th>\n","      <th>new_purchase_date_max</th>\n","      <th>new_purchase_date_min</th>\n","      <th>new_month_lag_min</th>\n","      <th>new_month_lag_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>67468</th>\n","      <td>915</td>\n","      <td>32</td>\n","      <td>21.0</td>\n","      <td>0.656250</td>\n","      <td>-18.102047</td>\n","      <td>-0.565689</td>\n","      <td>-0.027438</td>\n","      <td>-0.733429</td>\n","      <td>0.163252</td>\n","      <td>59</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.521044e+09</td>\n","      <td>1.521044e+09</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>40792</th>\n","      <td>306</td>\n","      <td>19</td>\n","      <td>18.0</td>\n","      <td>0.947368</td>\n","      <td>-11.924168</td>\n","      <td>-0.627588</td>\n","      <td>-0.346136</td>\n","      <td>-0.732933</td>\n","      <td>0.152228</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.000000</td>\n","      <td>1021998.0</td>\n","      <td>1.518890e+09</td>\n","      <td>1.517868e+09</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>138750</th>\n","      <td>854</td>\n","      <td>52</td>\n","      <td>38.0</td>\n","      <td>0.730769</td>\n","      <td>-34.827023</td>\n","      <td>-0.669750</td>\n","      <td>-0.313708</td>\n","      <td>-0.745405</td>\n","      <td>0.103801</td>\n","      <td>9</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>3.2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>0.447214</td>\n","      <td>2981123.0</td>\n","      <td>1.523427e+09</td>\n","      <td>1.520446e+09</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 45 columns</p>\n","</div>"],"text/plain":["        elapsed_time  hist_transactions_count  hist_authorized_flag_sum  \\\n","67468            915                       32                      21.0   \n","40792            306                       19                      18.0   \n","138750           854                       52                      38.0   \n","\n","        hist_authorized_flag_mean  hist_purchase_amount_sum  \\\n","67468                    0.656250                -18.102047   \n","40792                    0.947368                -11.924168   \n","138750                   0.730769                -34.827023   \n","\n","        hist_purchase_amount_mean  hist_purchase_amount_max  \\\n","67468                   -0.565689                 -0.027438   \n","40792                   -0.627588                 -0.346136   \n","138750                  -0.669750                 -0.313708   \n","\n","        hist_purchase_amount_min  hist_purchase_amount_std  \\\n","67468                  -0.733429                  0.163252   \n","40792                  -0.732933                  0.152228   \n","138750                 -0.745405                  0.103801   \n","\n","        hist_installments_sum        ...          new_installments_std  \\\n","67468                      59        ...                           0.0   \n","40792                       0        ...                           0.0   \n","138750                      9        ...                           0.0   \n","\n","        new_purchase_month_mean  new_purchase_month_max  \\\n","67468                       3.0                     3.0   \n","40792                       2.0                     2.0   \n","138750                      3.2                     4.0   \n","\n","        new_purchase_month_min  new_purchase_month_std  new_purchase_date_ptp  \\\n","67468                      3.0                0.000000                    0.0   \n","40792                      2.0                0.000000              1021998.0   \n","138750                     3.0                0.447214              2981123.0   \n","\n","        new_purchase_date_max  new_purchase_date_min  new_month_lag_min  \\\n","67468            1.521044e+09           1.521044e+09                1.0   \n","40792            1.518890e+09           1.517868e+09                1.0   \n","138750           1.523427e+09           1.520446e+09                1.0   \n","\n","        new_month_lag_max  \n","67468                 1.0  \n","40792                 1.0  \n","138750                2.0  \n","\n","[3 rows x 45 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"PsBYXCZN8hEU","colab_type":"code","outputId":"7b512ad3-3ecb-4026-d4c0-7ff6431d37bf","executionInfo":{"status":"ok","timestamp":1545468446937,"user_tz":-120,"elapsed":880,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":["#X_train = X_train.drop(['target'], axis=1)\n","Y_train = balanced['outliers_target']\n","balanced = balanced.drop(['outliers_target'], axis=1)\n","X_scaled = preprocessing.scale(balanced)\n","X_scaled = pd.DataFrame(data=X_scaled)\n","x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y_train, test_size=0.2, random_state=10)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\"Numerical issues were encountered \"\n"],"name":"stderr"}]},{"metadata":{"id":"oKFtHc2n8hCT","colab_type":"code","outputId":"4da827c4-27fe-48d2-eb8a-947867182c8f","executionInfo":{"status":"ok","timestamp":1545468641770,"user_tz":-120,"elapsed":9624,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":646}},"cell_type":"code","source":["model = Sequential()\n","  \n","model.add(Dense(50, activation='relu', input_shape=(45,)))\n","model.add(BatchNormalization())\n","\n","model.add(Dense(50, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='softmax'))\n","  \n","model.compile(loss='binary_crossentropy', optimizer='adam')\n","  \n","model.summary()\n","history1 = model.fit(X_scaled,Y_train,shuffle=True,epochs=10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_10 (Dense)             (None, 50)                2300      \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 50)                200       \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 50)                2550      \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 50)                200       \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 1)                 51        \n","=================================================================\n","Total params: 5,301\n","Trainable params: 5,101\n","Non-trainable params: 200\n","_________________________________________________________________\n","Epoch 1/10\n","12207/12207 [==============================] - 2s 134us/step - loss: 13.0600\n","Epoch 2/10\n","12207/12207 [==============================] - 1s 55us/step - loss: 13.0600\n","Epoch 3/10\n","12207/12207 [==============================] - 1s 56us/step - loss: 13.0600\n","Epoch 4/10\n","12207/12207 [==============================] - 1s 56us/step - loss: 13.0600\n","Epoch 5/10\n","12207/12207 [==============================] - 1s 55us/step - loss: 13.0600\n","Epoch 6/10\n","12207/12207 [==============================] - 1s 57us/step - loss: 13.0600\n","Epoch 7/10\n","12207/12207 [==============================] - 1s 58us/step - loss: 13.0600\n","Epoch 8/10\n","12207/12207 [==============================] - 1s 58us/step - loss: 13.0600\n","Epoch 9/10\n","12207/12207 [==============================] - 1s 55us/step - loss: 13.0600\n","Epoch 10/10\n","12207/12207 [==============================] - 1s 57us/step - loss: 13.0600\n"],"name":"stdout"}]},{"metadata":{"id":"hxnzYLsD8g_z","colab_type":"code","outputId":"cdbd36f8-7b2a-45fe-8cfd-31f99af7d502","executionInfo":{"status":"ok","timestamp":1545468684533,"user_tz":-120,"elapsed":4970,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"cell_type":"code","source":["clf = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=0)\n","clf.fit(X_scaled, Y_train)\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n","            max_depth=50, max_features='auto', max_leaf_nodes=None,\n","            min_impurity_decrease=0.0, min_impurity_split=None,\n","            min_samples_leaf=1, min_samples_split=2,\n","            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n","            oob_score=False, random_state=0, verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"UvPO9eN7KVaK","colab_type":"code","outputId":"04fb26cc-39fc-4ffe-b3c7-2e3ced6a4a23","executionInfo":{"status":"ok","timestamp":1545469541386,"user_tz":-120,"elapsed":634,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":253}},"cell_type":"code","source":["X_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>elapsed_time</th>\n","      <th>hist_transactions_count</th>\n","      <th>hist_authorized_flag_sum</th>\n","      <th>hist_authorized_flag_mean</th>\n","      <th>hist_purchase_amount_sum</th>\n","      <th>hist_purchase_amount_mean</th>\n","      <th>hist_purchase_amount_max</th>\n","      <th>hist_purchase_amount_min</th>\n","      <th>hist_purchase_amount_std</th>\n","      <th>hist_installments_sum</th>\n","      <th>...</th>\n","      <th>new_purchase_month_mean</th>\n","      <th>new_purchase_month_max</th>\n","      <th>new_purchase_month_min</th>\n","      <th>new_purchase_month_std</th>\n","      <th>new_purchase_date_ptp</th>\n","      <th>new_purchase_date_max</th>\n","      <th>new_purchase_date_min</th>\n","      <th>new_month_lag_min</th>\n","      <th>new_month_lag_max</th>\n","      <th>outliers_target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>245</td>\n","      <td>260</td>\n","      <td>247.0</td>\n","      <td>0.950000</td>\n","      <td>-165.968730</td>\n","      <td>-0.638341</td>\n","      <td>2.258395</td>\n","      <td>-0.739395</td>\n","      <td>0.212139</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>3.478261</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>0.510754</td>\n","      <td>4742309.0</td>\n","      <td>1.525001e+09</td>\n","      <td>1.520259e+09</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>396</td>\n","      <td>350</td>\n","      <td>339.0</td>\n","      <td>0.968571</td>\n","      <td>-210.006330</td>\n","      <td>-0.600018</td>\n","      <td>4.630300</td>\n","      <td>-0.742400</td>\n","      <td>0.384967</td>\n","      <td>543</td>\n","      <td>...</td>\n","      <td>2.500000</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>0.547723</td>\n","      <td>4887632.0</td>\n","      <td>1.522393e+09</td>\n","      <td>1.517505e+09</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>549</td>\n","      <td>43</td>\n","      <td>41.0</td>\n","      <td>0.953488</td>\n","      <td>-29.167390</td>\n","      <td>-0.678311</td>\n","      <td>-0.145847</td>\n","      <td>-0.730138</td>\n","      <td>0.087380</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>4.000000</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.524937e+09</td>\n","      <td>1.524937e+09</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>153</td>\n","      <td>77</td>\n","      <td>77.0</td>\n","      <td>1.000000</td>\n","      <td>-49.491364</td>\n","      <td>-0.642745</td>\n","      <td>1.445596</td>\n","      <td>-0.740897</td>\n","      <td>0.261624</td>\n","      <td>84</td>\n","      <td>...</td>\n","      <td>3.714286</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>0.487950</td>\n","      <td>3625505.0</td>\n","      <td>1.524049e+09</td>\n","      <td>1.520424e+09</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>92</td>\n","      <td>133</td>\n","      <td>128.0</td>\n","      <td>0.962406</td>\n","      <td>-48.687656</td>\n","      <td>-0.366073</td>\n","      <td>7.193041</td>\n","      <td>-0.746156</td>\n","      <td>1.352094</td>\n","      <td>182</td>\n","      <td>...</td>\n","      <td>3.555556</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>0.503953</td>\n","      <td>4949682.0</td>\n","      <td>1.524941e+09</td>\n","      <td>1.519992e+09</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 46 columns</p>\n","</div>"],"text/plain":["   elapsed_time  hist_transactions_count  hist_authorized_flag_sum  \\\n","0           245                      260                     247.0   \n","1           396                      350                     339.0   \n","2           549                       43                      41.0   \n","3           153                       77                      77.0   \n","4            92                      133                     128.0   \n","\n","   hist_authorized_flag_mean  hist_purchase_amount_sum  \\\n","0                   0.950000               -165.968730   \n","1                   0.968571               -210.006330   \n","2                   0.953488                -29.167390   \n","3                   1.000000                -49.491364   \n","4                   0.962406                -48.687656   \n","\n","   hist_purchase_amount_mean  hist_purchase_amount_max  \\\n","0                  -0.638341                  2.258395   \n","1                  -0.600018                  4.630300   \n","2                  -0.678311                 -0.145847   \n","3                  -0.642745                  1.445596   \n","4                  -0.366073                  7.193041   \n","\n","   hist_purchase_amount_min  hist_purchase_amount_std  hist_installments_sum  \\\n","0                 -0.739395                  0.212139                      4   \n","1                 -0.742400                  0.384967                    543   \n","2                 -0.730138                  0.087380                      0   \n","3                 -0.740897                  0.261624                     84   \n","4                 -0.746156                  1.352094                    182   \n","\n","        ...         new_purchase_month_mean  new_purchase_month_max  \\\n","0       ...                        3.478261                     4.0   \n","1       ...                        2.500000                     3.0   \n","2       ...                        4.000000                     4.0   \n","3       ...                        3.714286                     4.0   \n","4       ...                        3.555556                     4.0   \n","\n","   new_purchase_month_min  new_purchase_month_std  new_purchase_date_ptp  \\\n","0                     3.0                0.510754              4742309.0   \n","1                     2.0                0.547723              4887632.0   \n","2                     4.0                0.000000                    0.0   \n","3                     3.0                0.487950              3625505.0   \n","4                     3.0                0.503953              4949682.0   \n","\n","   new_purchase_date_max  new_purchase_date_min  new_month_lag_min  \\\n","0           1.525001e+09           1.520259e+09                1.0   \n","1           1.522393e+09           1.517505e+09                1.0   \n","2           1.524937e+09           1.524937e+09                2.0   \n","3           1.524049e+09           1.520424e+09                1.0   \n","4           1.524941e+09           1.519992e+09                1.0   \n","\n","   new_month_lag_max  outliers_target  \n","0                2.0                0  \n","1                2.0                0  \n","2                2.0                0  \n","3                2.0                0  \n","4                2.0                0  \n","\n","[5 rows x 46 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"n63dvjo28g3m","colab_type":"code","outputId":"92bbec78-9965-4786-ec6c-aebdb23d8056","executionInfo":{"status":"ok","timestamp":1545469662299,"user_tz":-120,"elapsed":4780,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["Y_train = X_train['outliers_target'] \n","X_train1 = X_train.drop('outliers_target', axis=1)\n","X_train1 = preprocessing.scale(X_train1)\n","clf.score(X_train1,Y_train)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\"Numerical issues were encountered \"\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.9321503390006785"]},"metadata":{"tags":[]},"execution_count":22}]},{"metadata":{"id":"qldxZtlK8g1L","colab_type":"code","outputId":"31a2dd22-26e1-4153-be67-034de910e669","executionInfo":{"status":"ok","timestamp":1545469772829,"user_tz":-120,"elapsed":4731,"user":{"displayName":"Elior Nehemya","photoUrl":"","userId":"03377496704646286933"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["pred = clf.predict(X_train1)\n","confusion_matrix(Y_train, pred)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[186712,  12998],\n","       [   702,   1505]])"]},"metadata":{"tags":[]},"execution_count":23}]},{"metadata":{"id":"8xKZ5O92Lr10","colab_type":"text"},"cell_type":"markdown","source":["as we can see our clasifier may have high accuracy but its not enough. the confusion matrix shows that its fals positive may cost too much for the total loss."]}]}